{"meta":{"title":"技术小站","subtitle":null,"description":null,"author":"ZhangHutao","url":"https://hutaozhang.github.io","root":"/"},"pages":[{"title":"about","date":"2020-06-04T10:11:54.000Z","updated":"2021-01-27T12:10:16.857Z","comments":true,"path":"about/index.html","permalink":"https://hutaozhang.github.io/about/index.html","excerpt":"","text":""},{"title":"box","date":"2021-01-31T15:22:08.000Z","updated":"2021-01-31T15:22:08.515Z","comments":true,"path":"box/index.html","permalink":"https://hutaozhang.github.io/box/index.html","excerpt":"","text":""},{"title":"分类","date":"2021-01-20T18:55:13.533Z","updated":"2021-01-20T18:55:13.533Z","comments":true,"path":"categories/index.html","permalink":"https://hutaozhang.github.io/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2021-01-21T17:28:39.374Z","updated":"2021-01-21T17:28:39.374Z","comments":true,"path":"tags/index.html","permalink":"https://hutaozhang.github.io/tags/index.html","excerpt":"","text":""},{"title":"朋友","date":"2021-01-22T17:28:40.246Z","updated":"2021-01-22T17:28:40.246Z","comments":true,"path":"friends/index.html","permalink":"https://hutaozhang.github.io/friends/index.html","excerpt":"","text":""}],"posts":[{"title":"Spring 事务","slug":"Spring事务","date":"2021-03-08T11:05:45.244Z","updated":"2021-03-08T11:10:55.501Z","comments":true,"path":"posts/40486.html","link":"","permalink":"https://hutaozhang.github.io/posts/40486.html","excerpt":"","text":"Spring的事务管理 Spring事务本质是对数据库事务的支持，如果数据库不支持事务（例如MySQL的MyISAM引擎不支持事务），则Spring事务也不会生效。 Spring 既支持编程式事务管理, 也支持声明式的事务管理. 编程式事务管理将事务管理代码嵌入到业务方法中来控制事务的提交和回滚。在编程式管理事务时, 必须在每个事务操作中包含额外的事务管理代码。 声明式的事务管理它将事务管理代码从业务方法中分离出来, 以声明的方式来实现事务管理。事务管理作为一种横切关注点, 可以通过 AOP 方法模块化。Spring 通过 Spring AOP 框架支持声明式事务管理。 Spring事务管理 Spring并不直接管理事务，而是提供了多种事务管理器，他们将事务管理的职责委托给Hibernate或者JTA等持久化机制所提供的相关平台框架的事务来实现。 Spring事务管理器的接口是org.springframework.transaction.PlatformTransactionManager，通过这个接口，Spring为各个平台如JDBC、Hibernate等都提供了对应的事务管理器，但是具体的实现就是各个平台自己的事情了。 SSM中，一般spring自己管理事务，属于声明式管理，如果让MyBatis来管理事务，会导致api形式的调用，也就是编程式事务。 此接口的内容如下： 12345678Public interface PlatformTransactionManager() &#123; // 由TransactionDefinition得到TransactionStatus对象 TransactionStatus getTransaction(TransactionDefinition definition) throws TransactionException; // 提交 Void commit(TransactionStatus status) throws TransactionException; // 回滚 Void rollback(TransactionStatus status) throws TransactionException; &#125; 从这里可知具体的具体的事务管理机制对Spring来说是透明的，它并不关心那些，那些是对应各个平台需要关心的，所以Spring事务管理的一个优点就是为不同的事务API提供一致的编程模型，如JTA、JDBC、Hibernate、JPA。 运行流程示例如下： Spring 中的事务管理器的不同实现 ① DataSourceTransactionManager 在应用程序中只需要处理一个数据源，而且通过JDBC存取。 1234&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt; 实际上，DataSourceTransactionManager是通过调用java.sql.Connection来管理事务，而后者是通过DataSource获取到的。通过调用连接的commit()方法来提交事务，同样，事务失败则通过调用rollback()方法进行回滚。 ② JtaTransactionManager 在JAVAEE应用服务器上用JTA(Java Transaction API)进行事务管理。 ③ HibernateTransactionManager 如果应用程序的持久化是通过Hibernate实习的，那么你需要使用HibernateTransactionManager。 对于Hibernate3，需要在Spring上下文定义中添加如下的&lt;bean&gt;声明： 1234&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.orm.hibernate3.HibernateTransactionManager&quot;&gt; &lt;property name=&quot;sessionFactory&quot; ref=&quot;sessionFactory&quot; /&gt;&lt;/bean&gt; sessionFactory属性需要装配一个Hibernate的session工厂，HibernateTransactionManager的实现细节是它将事务管理的职责委托org.hibernate.Transaction对象，而后者是从Hibernate Session中获取到的。 当事务成功完成时，HibernateTransactionManager将会调用Transaction对象的commit()方法，反之，将会调用rollback()方法。 Spring用事务通知声明式地管理事务 事务管理是一种横切关注点 ① &lt;tx:advice&gt; 元素定义 为了在 Spring 2.x 中启用声明式事务管理, 可以通过 tx Schema 中定义的 &lt;tx:advice&gt; 元素声明事务通知, 为此必须事先将这个 Schema 定义添加到 &lt;beans&gt; 根元素中去。 1234567&lt;tx:advice id=&quot;txadvice&quot; transaction-manager=&quot;transactionManager&quot; &gt; &lt;tx:attributes&gt; &lt;!-- 根据方法名指定事务的属性 --&gt; &lt;tx:method name=&quot;purchase&quot; propagation=&quot;REQUIRES_NEW&quot; isolation=&quot;READ_COMMITTED&quot; /&gt; &lt;tx:method name=&quot;*&quot;/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; ② 声明了事务通知后, 就需要将它与切入点关联起来. 由于事务通知是在 aop:config 元素外部声明的, 所以它无法直接与切入点产生关联. 所以必须在aop:config 元素中声明一个增强器通知与切入点关联起来. 1&lt;aop:advisor advice-ref=&quot;txadvice&quot; pointcut-ref=&quot;txPointCut&quot; /&gt; 由于 Spring AOP 是基于代理的方法, 所以只能增强公共方法. 因此, 只有公有方法才能通过 Spring AOP 进行事务管理。 Spring的事务传播 事务传播行为是指一个事务方法A被另一个事务方法B调用时，这个事务A应该如何处理。事务A应该在事务B中运行还是另起一个事务，这个有事务A的传播行为决定。 事务传播属性定义TransactionDefinition 1234567int PROPAGATION_REQUIRED = 0;int PROPAGATION_SUPPORTS = 1;int PROPAGATION_MANDATORY = 2;int PROPAGATION_REQUIRES_NEW = 3;int PROPAGATION_NOT_SUPPORTED = 4;int PROPAGATION_NEVER = 5;int PROPAGATION_NESTED = 6; 常量名称 解释 PROPAGATION_REQUIRED 支持当前事务，如果当前没有事务，就新建一个事务。这是Spring 默认的事务的传播。 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行。 PROPAGATION_MANDATORY 支持当前事务，如果当前没有事务，就抛出异常。 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。新建的事务将和被挂起的事务没有任何关系，是两个独立的事务，外层事务失败回滚之后， 不能回滚内层事务执行的结果，内层事务失败抛出异常，外层事务捕获， 也可以不处理回滚操作。 使用JtaTransactionManager作为事务管理器 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。使用JtaTransactionManager作为事务管理器 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED 如果一个活动的事务存在，则运行在一个嵌套的事务中。如果没有活动事务，则按REQUIRED属性执行。它使用了一个单独的事务，这个事务拥有多个可以回滚的保存点。内部事务的回滚不会对外部事务造成影响。它只对DataSourceTransactionManager事务管理器起效。 PROPAGATION_REQUIRED PROPAGATION_SUPPORTS PROPAGATION_MANDATORY PROPAGATION_REQUIRES_NEW PROPAGATION_NOT_SUPPORTED PROPAGATION_NEVER PROPAGATION_NESTED Spring事务的隔离级别 事务隔离级别定义TransactionDefinition 12345int ISOLATION_DEFAULT = -1;int ISOLATION_READ_UNCOMMITTED = 1;int ISOLATION_READ_COMMITTED = 2;int ISOLATION_REPEATABLE_READ = 4;int ISOLATION_SERIALIZABLE = 8;| 隔离级别 | 解释 ||:————————–:|:———————————————————————————————————————–:|| ISOLATION_DEFAULT | 这是个 PlatfromTransactionManager 默认的隔离级别， 使用数据库默认的事务隔离级别。另外四个与 JDBC 的 隔离级别相对应。 || ISOLATION_READ_UNCOMMITTED | 这是事务最低的隔离级别，它允许另外一个事务可以看 到这个事务未提交的数据。这种隔离级别会产生脏读， 不可重复读和幻像读。 || ISOLATION_READ_COMMITTED | 保证一个事务修改的数据提交后才能被另外一个事务读 取。另外一个事务不能读取该事务未提交的数据。 ISOLATION_REPEATABLE_READ || ISOLATION_SERIALIZABLE | 这是花费最高代价但是最可靠的事务隔离级别。事务被 处理为顺序执行。 | Spring事务基本配置样例 12345678910111213141516171819202122&lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot;/&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;&lt;/bean&gt;&lt;tx:advice id=&quot;transactionAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;add*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception,RuntimeException,SQLException&quot;/&gt; &lt;tx:method name=&quot;remove*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception,RuntimeException,SQLException&quot;/&gt; &lt;tx:method name=&quot;edit*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception,RuntimeException,SQLException&quot;/&gt; &lt;tx:method name=&quot;login&quot; propagation=&quot;NOT_SUPPORTED&quot;/&gt; &lt;tx:method name=&quot;query*&quot; read-only=&quot;true&quot;/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;aop:config&gt; &lt;aop:advisor advice-ref=&quot;transactionAdvice&quot; pointcut-ref=&quot;transactionPointcut&quot;/&gt; &lt;aop:aspect ref=&quot;dataSource&quot;&gt; &lt;aop:pointcut id=&quot;transactionPointcut&quot; expression=&quot;execution(public * com.gupaoedu..*.service..*Service.*(..))&quot; /&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt;","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"Spring","slug":"教程/Spring","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Spring/"}],"tags":[{"name":"事务","slug":"事务","permalink":"https://hutaozhang.github.io/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"Transaction","slug":"Transaction","permalink":"https://hutaozhang.github.io/tags/Transaction/"},{"name":"Spring","slug":"Spring","permalink":"https://hutaozhang.github.io/tags/Spring/"}]},{"title":"数据库","slug":"数据库","date":"2021-03-07T09:54:35.889Z","updated":"2021-03-08T11:05:13.371Z","comments":true,"path":"posts/63394.html","link":"","permalink":"https://hutaozhang.github.io/posts/63394.html","excerpt":"","text":"数据库事务Database 事务 Database 事务ACID特性 Spring 事务 面试 MySQL 事务 索引MySQL 索引 面试 MySQL 索引 MVCC面试 MySQL MVCC","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://hutaozhang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"MySQL 索引","slug":"MySQL索引","date":"2021-03-06T14:01:00.941Z","updated":"2021-03-08T10:02:48.533Z","comments":true,"path":"posts/58986.html","link":"","permalink":"https://hutaozhang.github.io/posts/58986.html","excerpt":"","text":"一、索引概述1. 简介2. 索引的原理 MySQL支持诸多存储引擎，而各种存储引擎对索引的支持也各不相同，因此MySQL数据库支持多种索引类型，如BTree索引，B+Tree索引，哈希索引，全文索引等等， 哈希索引 只有memory（内存）存储引擎支持哈希索引，哈希索引用索引列的值计算该值的hashCode，然后在hashCode相应的位置存执该值所在行数据的物理位置，因为使用散列算法，因此访问速度非常快，但是一个值只能对应一个hashCode，而且是散列的分布方式，因此哈希索引不支持范围查找和排序的功能。 全文索引 FULLTEXT（全文）索引，仅可用于MyISAM和InnoDB，针对较大的数据，生成全文索引非常的消耗时间和空间。对于文本的大对象，或者较大的CHAR类型的数据，如果使用普通索引，那么匹配文本前几个字符还是可行的，但是想要匹配文本中间的几个单词，那么就要使用LIKE %word%来匹配，这样需要很长的时间来处理，响应时间会大大增加，这种情况，就可使用时FULLTEXT索引了，在生成FULLTEXT索引时，会为文本生成一份单词的清单，在索引时及根据这个单词的清单来索引。FULLTEXT可以在创建表的时候创建，也可以在需要的时候用ALTER或者CREATE INDEX来添加： 1234567//创建表的时候添加FULLTEXT索引CTREATE TABLE my_table( id INT(10) PRIMARY KEY, name VARCHAR(10) NOT NULL, my_text TEXT, FULLTEXT(my_text))ENGINE=MyISAM DEFAULT CHARSET=utf8; 12//创建表以后，在需要的时候添加FULLTEXT索引ALTER TABLE my_table ADD FULLTEXT INDEX ft_index(column_name); 全文索引的查询也有自己特殊的语法，而不能使用LIKE %查询字符串%的模糊查询语法 1SELECT * FROM table_name MATCH(ft_index) AGAINST(&#x27;查询字符串&#x27;); BTree索引和B+Tree索引 BTree索引 BTree是平衡搜索多叉树，设树的度为2d（d&gt;1），高度为h，那么BTree要满足以一下条件： 每个叶子结点的高度一样，等于h； 每个非叶子结点由n-1个key和n个指针point组成，其中d&lt;=n&lt;=2d,key和point相互间隔，结点两端一定是key； 叶子结点指针都为null； 非叶子结点的key都是[key,data]二元组，其中key表示作为索引的键，data为键值所在行的数据； BTree的结构如下：在BTree的机构下，就可以使用二分查找的查找方式，查找复杂度为h*log(n)，一般来说树的高度是很小的，一般为3左右，因此BTree是一个非常高效的查找结构。 B+Tree索引B+Tree是BTree的一个变种，设d为树的度数，h为树的高度，B+Tree和BTree的不同主要在于： B+Tree中的非叶子结点不存储数据，只存储键值； B+Tree的叶子结点没有指针，所有键值都会出现在叶子结点上，且key存储的键值对应data数据的物理地址； B+Tree的每个非叶子节点由n个键值key和n个指针point组成； B+Tree的结构图如下： B+Tree对比BTree的优点： 1、磁盘读写代价更低 一般来说B+Tree比BTree更适合实现外存的索引结构，因为存储引擎的设计专家巧妙的利用了外存（磁盘）的存储结构，即磁盘的最小存储单位是扇区（sector），而操作系统的块（block）通常是整数倍的sector，操作系统以页（page）为单位管理内存，一页（page）通常默认为4K，数据库的页通常设置为操作系统页的整数倍，因此索引结构的节点被设计为一个页的大小，然后利用外存的“预读取”原则，每次读取的时候，把整个节点的数据读取到内存中，然后在内存中查找，已知内存的读取速度是外存读取I/O速度的几百倍，那么提升查找速度的关键就在于尽可能少的磁盘I/O，那么可以知道，每个节点中的key个数越多，那么树的高度越小，需要I/O的次数越少，因此一般来说B+Tree比BTree更快，因为B+Tree的非叶节点中不存储data，就可以存储更多的key。 2、查询速度更稳定 由于B+Tree非叶子节点不存储数据（data），因此所有的数据都要查询至叶子节点，而叶子节点的高度都是相同的，因此所有数据的查询速度都是一样的。 带顺序索引的B+Tree很多存储引擎在B+Tree的基础上进行了优化，添加了指向相邻叶节点的指针，形成了带有顺序访问指针的B+Tree，这样做是为了提高区间查找的效率，只要找到第一个值那么就可以顺序的查找后面的值。 B+Tree的结构图如下： 聚簇索引和非聚簇索引 分析了MySQL的索引结构的实现原理，然后我们来看看具体的存储引擎怎么实现索引结构的，MySQL中最常见的两种存储引擎分别是MyISAM和InnoDB，分别实现了非聚簇索引和聚簇索引。 聚簇索引的解释是:聚簇索引的顺序就是数据的物理存储顺序 非聚簇索引的解释是:索引顺序与数据物理排列顺序无关 （这样说起来并不好理解，让人摸不着头脑，清继续看下文，并在插图下方对上述两句话有解释） 首先要介绍几个概念，在索引的分类中，我们可以按照索引的键是否为主键来分为“主索引”和“辅助索引”，使用主键键值建立的索引称为“主索引”，其它的称为“辅助索引”。因此主索引只能有一个，辅助索引可以有很多个。 3. 索引的优缺点 优势：可以快速检索，减少I/O次数，加快检索速度；根据索引分组和排序，可以加快分组和排序； 劣势：索引本身也是表，因此会占用存储空间，一般来说，索引表占用的空间的数据表的1.5倍；索引表的维护和创建需要时间成本，这个成本随着数据量增大而增大；构建索引会降低数据表的修改操作（删除，添加，修改）的效率，因为在修改数据表的同时还需要修改索引表； 二、索引的使用场景 数据库中表的数据量较大的情况下，对于查询响应时间不能满足业务需求，可以合理的使用索引提升查询效率。 三、索引的分类和创建和修改删除等命令1. 基本索引类型 ① 普通索引（单列索引） 创建普通索引 1ALTER TABLE table_name ADD INDEX index_name (column); 创建组合索引 1ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3); ② 唯一索引用来建立索引的列的值必须是唯一的，允许空值 1ALTER TABLE &#x27;table_name&#x27; ADD UNIQUE index_name(&#x27;col&#x27;)； ④ 主键索引数据列不允许重复，不允许为NULL，一个表只能有一个主键。 ⑤ 全文索引是目前搜索引擎使用的一种关键技术。 1ALTER TABLE table_name ADD FULLTEXT (column); 2. 创建的语句 12CREATE TABLE table_name[col_name data type][unique|fulltext][index|key][index_name](col_name[length])[asc|desc] unique|fulltext为可选参数，分别表示唯一索引、全文索引 index和key为同义词，两者作用相同，用来指定创建索引 col_name为需要创建索引的字段列，该列必须从数据表中该定义的多个列中选择 index_name指定索引的名称，为可选参数，如果不指定，默认col_name为索引值 length为可选参数，表示索引的长度，只有字符串类型的字段才能指定索引长度 asc或desc指定升序或降序的索引值存储 3. 索引的创建、查询和删除 索引的创建 普通索引（单列索引）单列索引是最基本的索引，它没有任何限制。 直接创建索引 1CREATE INDEX index_name ON table_name(col_name); 修改表结构的方式添加索引 1ALTER TABLE table_name ADD INDEX index_name(col_name); 创建表的时候同时创建索引12345678CREATE TABLE `news` ( `id` int(11) NOT NULL AUTO_INCREMENT , `title` varchar(255) NOT NULL , `content` varchar(255) NULL , `time` varchar(20) NULL DEFAULT NULL , PRIMARY KEY (`id`), INDEX index_name (title(255))) 删除索引123DROP INDEX index_name ON table_name;或者alter table `表名` drop index 索引名; 复合索引（组合索引） 唯一索引 主键索引 全文索引 四、简单实例演示","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"MySQL","slug":"教程/MySQL","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/MySQL/"}],"tags":[{"name":"索引","slug":"索引","permalink":"https://hutaozhang.github.io/tags/%E7%B4%A2%E5%BC%95/"},{"name":"Index","slug":"Index","permalink":"https://hutaozhang.github.io/tags/Index/"},{"name":"MySQL","slug":"MySQL","permalink":"https://hutaozhang.github.io/tags/MySQL/"}]},{"title":"Database 索引","slug":"Database索引","date":"2021-03-06T13:40:50.006Z","updated":"2021-03-07T10:07:56.665Z","comments":true,"path":"posts/28156.html","link":"","permalink":"https://hutaozhang.github.io/posts/28156.html","excerpt":"","text":"一、 数据库索引数据库索引定义 索引是对数据库表中一列或多列的值进行排序的一种结构，使用索引可快速访问数据库表中的特定信息。索引的一个主要目的就是加快检索表中数据，亦即能协助信息搜索者尽快的找到符合限制条件的记录ID的辅助数据结构。 简而言之： 索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。 数据库索引类别 数据库索引好比是一本书前面的目录，能加快数据库的查询速度。索引分为聚簇索引和非聚簇索引两种： 聚簇索引 是按照数据存放的物理位置为顺序的，而非聚簇索引就不一样了；聚簇索引能提高多行检索的速度，而非聚簇索引对于单行的检索很快。 根据数据库的功能，可以在数据库设计器中创建三种索引：唯一索引、主键索引和聚集索引。有关数据库所支持的索引功能的详细信息，请参见数据库文档。 提示：尽管唯一索引有助于定位信息，但为获得最佳性能结果，建议改用主键或唯一约束。 唯一索引 唯一索引是不允许其中任何两行具有相同索引值的索引。当现有数据中存在重复的键值时，大多数数据库不允许将新创建的唯一索引与表一起保存。数据库还可能防止添加将在表中创建重复键值的新数据。例如，如果在employee表中职员的姓(lname)上创建了唯一索引，则任何两个员工都不能同姓。 主键索引 数据库表经常有一列或多列组合，其值唯一标识表中的每一行。该列称为表的主键。在数据库关系图中为表定义主键将自动创建主键索引，主键索引是唯一索引的特定类型。该索引要求主键中的每个值都唯一。当在查询中使用主键索引时，它还允许对数据的快速访问。 *聚集索引 在聚集索引中，表中行的物理顺序与键值的逻辑（索引）顺序相同。一个表只能包含一个聚集索引。如果某索引不是聚集索引，则表中行的物理顺序与键值的逻辑顺序不匹配。与非聚集索引相比，聚集索引通常提供更快的数据访问速度。聚集索引和非聚集索引的区别，如字典默认按字母顺序排序，读者如知道某个字的读音可根据字母顺序快速定位。因此聚集索引和表的内容是在一起的。如读者需查询某个生僻字，则需按字典前面的索引，举例按偏旁进行定位，找到该字对应的页数，再打开对应页数找到该字。这种通过两个地方而查询到某个字的方式就如非聚集索引。 索引列 可以基于数据库表中的单列或多列创建索引。多列索引可以区分其中一列可能有相同值的行。如果经常同时搜索两列或多列或按两列或多列排序时，索引也很有帮助。例如，如果经常在同一查询中为姓和名两列设置判据，那么在这两列上创建多列索引将很有意义。 检查查询的WHERE和JOIN子句。在任一子句中包括的每一列都是索引可以选择的对象。对新索引进行试验以检查它对运行查询性能的影响。考虑已在表上创建的索引数量。最好避免在单个表上有很多索引。检查已在表上创建的索引的定义。最好避免包含共享列的重叠索引。 检查某列中唯一数据值的数量，并将该数量与表中的行数进行比较。比较的结果就是该列的可选择性，这有助于确定该列是否适合建立索引，如果适合，确定索引的类型。 数据库索引特性 基本特点 建立索引的目的是加快对表中记录的查找或排序。为表设置索引要付出代价的：一是增加了数据库的存储空间，二是在插入和修改数据时要花费较多的时间(因为索引也要随之变动)。数据库索引就是为了提高表的搜索效率而对某些字段中的值建立的目录 。 创建索引可以大大提高系统的性能。第一，通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。第二，可以大大加快数据的检索速度，这也是创建索引的最主要的原因。第三，可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。第四，在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。第五，通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 因为，增加索引也有许多不利的方面。第一，创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。第二，索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。第三，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。 优点 通过建立索引可以极大地提高在数据库中获取所需信息的速度，同时还能提高服务器处理相关搜索请求的效率，从这个方面来看它具有以下优点 ： 在设计数据库时，通过创建一个惟一的索引，能够在索引和信息之间形成一对一的映射式的对应关系，增加数据的惟一性特点。 能提高数据的搜索及检索速度，符合数据库建立的初衷。 能够加快表与表之间的连接速度，这对于提高数据的参考完整性方面具有重要作用。 在信息检索过程中，若使用分组及排序子句进行时，通过建立索引能有效的减少检索过程中所需的分组及排序时间，提高检索效率。 建立索引之后，在信息查询过程中可以使用优化隐藏器，这对于提高整个信息检索系统的性能具有重要意义。 缺点 虽然索引的建立在提高检索效率方面具有诸多积极的作用，但还是存在下列缺点： 在数据库建立过程中，需花费较多的时间去建立并维护索引，特别是随着数据总量的增加，所花费的时间将不断递增。 在数据库中创建的索引需要占用一定的物理存储空间，这其中就包括数据表所占的数据空间以及所创建的每一个索引所占用的物理空间，如果有必要建立起聚簇索引，所占用的空间还将进一步的增加 在对表中的数据进行修改时，例如对其进行增加、删除或者是修改操作时，索引还需要进行动态的维护，这给数据库的维护速度带来了一定的麻烦。 注意事项 索引是建立在数据库表中的某些列的上面。在创建索引的时候，应该考虑在哪些列上可以创建索引，在哪些列上不能创建索引。一般来说，应该在这些列上创建索引： 在经常需要搜索的列上，可以加快搜索的速度； 在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构； 在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度；在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的； 在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间； 在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。 同样，对于有些列不应该创建索引。一般来说，不应该创建索引的这些列具有下列特点： 第一，对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 第二，对于那些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。 第三，对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少,不利于使用索引。 第四，当修改性能远远大于检索性能时，不应该创建索引。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改操作远远多于检索操作时，不应该创建索引。","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"Database","slug":"教程/Database","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Database/"}],"tags":[{"name":"Database","slug":"Database","permalink":"https://hutaozhang.github.io/tags/Database/"},{"name":"索引","slug":"索引","permalink":"https://hutaozhang.github.io/tags/%E7%B4%A2%E5%BC%95/"},{"name":"Index","slug":"Index","permalink":"https://hutaozhang.github.io/tags/Index/"}]},{"title":"面试 MySQL MVCC","slug":"面试-MySQLMVCC","date":"2021-03-06T13:40:23.288Z","updated":"2021-03-07T10:03:22.624Z","comments":true,"path":"posts/2460.html","link":"","permalink":"https://hutaozhang.github.io/posts/2460.html","excerpt":"","text":"一、前提概要 MVCCMVCC，全称Multi-Version Concurrency Control，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。 什么是MVCC? MVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读 什么是当前读和快照读？ 在学习MVCC多版本并发控制之前，我们必须先了解一下，什么是MySQL InnoDB下的当前读和快照读? 当前读像select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。 快照读像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本 说白了MVCC就是为了实现读-写冲突不加锁，而这个读指的就是快照读, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现 当前读，快照读和MVCC的关系 准确的说，MVCC多版本并发控制指的是 “维持一个数据的多个版本，使得读写操作没有冲突” 这么一个概念。仅仅是一个理想概念 而在MySQL中，实现这么一个MVCC理想概念，我们就需要MySQL提供具体的功能去实现它，而快照读就是MySQL为我们实现MVCC理想模型的其中一个具体非阻塞读功能。而相对而言，当前读就是悲观锁的具体功能实现 要说的再细致一些，快照读本身也是一个抽象概念，再深入研究。MVCC模型在MySQL中的具体实现则是由 3个隐式字段，undo日志 ，Read View 等去完成的，具体可以看下面的MVCC实现原理 MVCC能解决什么问题，好处是？ 数据库并发场景有三种，分别为： 读-读：不存在任何问题，也不需要并发控制 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读 写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失 MVCC带来的好处是？ 多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 所以MVCC可以为数据库解决以下问题 在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能 同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题 小结一下 总之，MVCC就是因为大牛们，不满意只让数据库采用悲观锁这样性能不佳的形式去解决读-写冲突问题，而提出的解决方案，所以在数据库中，因为有了MVCC，所以我们可以形成两个组合： MVCC + 悲观锁MVCC解决读写冲突，悲观锁解决写写冲突 MVCC + 乐观锁MVCC解决读写冲突，乐观锁解决写写冲突这种组合的方式就可以最大程度的提高数据库并发性能，并解决读写冲突，和写写冲突导致的问题 二、MVCC的实现原理 MVCC的目的就是多版本并发控制，在数据库中的实现，就是为了解决读写冲突，它的实现原理主要是依赖记录中的 3个隐式字段，undo日志 ，Read View 来实现的。所以我们先来看看这个三个point的概念 隐式字段 每行记录除了我们自定义的字段外，还有数据库隐式定义的DB_TRX_ID,DB_ROLL_PTR,DB_ROW_ID等字段 DB_TRX_ID6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID DB_ROLL_PTR7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里） DB_ROW_ID6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引实际还有一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了 如上图，DB_ROW_ID是数据库默认为该行记录生成的唯一隐式主键，DB_TRX_ID是当前操作该记录的事务ID,而DB_ROLL_PTR是一个回滚指针，用于配合undo日志，指向上一个旧版本 undo日志 undo log主要分为两种： insert undo log代表事务在insert新记录时产生的undo log, 只在事务回滚时需要，并且在事务提交后可以被立即丢弃 update undo log事务在进行update或delete时产生的undo log; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除 purge 从前面的分析可以看出，为了实现InnoDB的MVCC机制，更新或者删除操作都只是设置一下老记录的deleted_bit，并不真正将过时的记录删除。 为了节省磁盘空间，InnoDB有专门的purge线程来清理deleted_bit为true的记录。为了不影响MVCC的正常工作，purge线程自己也维护了一个read view（这个read view相当于系统中最老活跃事务的read view）;如果某个记录的deleted_bit为true，并且DB_TRX_ID相对于purge线程的read view可见，那么这条记录一定是可以被安全清除的。 对MVCC有帮助的实质是update undo log ，undo log实际上就是存在rollback segment中旧记录链，它的执行流程如下： 一、 比如一个有个事务插入persion表插入了一条新记录，记录如下，name为Jerry, age为24岁，隐式主键是1，事务ID和回滚指针，我们假设为NULL二、 现在来了一个事务1对该记录的name做出了修改，改为Tom 在事务1修改该行(记录)数据时，数据库会先对该行加排他锁 然后把该行数据拷贝到undo log中，作为旧记录，既在undo log中有当前行的拷贝副本 拷贝完毕后，修改该行name为Tom，并且修改隐藏字段的事务ID为当前事务1的ID, 我们默认从1开始，之后递增，回滚指针指向拷贝到undo log的副本记录，既表示我的上一个版本就是它 事务提交后，释放锁三、 又来了个事务2修改person表的同一个记录，将age修改为30岁 在事务2修改该行数据时，数据库也先为该行加锁 然后把该行数据拷贝到undo log中，作为旧记录，发现该行记录已经有undo log了，那么最新的旧数据作为链表的表头，插在该行记录的undo log最前面 修改该行age为30岁，并且修改隐藏字段的事务ID为当前事务2的ID, 那就是2，回滚指针指向刚刚拷贝到undo log的副本记录 事务提交，释放锁从上面，我们就可以看出，不同事务或者相同事务的对同一记录的修改，会导致该记录的undo log成为一条记录版本线性表，既链表，undo log的链首就是最新的旧记录，链尾就是最早的旧记录（当然就像之前说的该undo log的节点可能是会purge线程清除掉，向图中的第一条insert undo log，其实在事务提交之后可能就被删除丢失了，不过这里为了演示，所以还放在这里） Read View(读视图) 什么是Read View? 什么是Read View，说白了Read View就是事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID(当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大) 所以我们知道 Read View主要是用来做可见性判断的, 即当我们某个事务执行快照读的时候，对该记录创建一个Read View读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。 Read View遵循一个可见性算法，主要是将要被修改的数据的最新记录中的DB_TRX_ID（即当前事务ID）取出来，与系统当前其他活跃事务的ID去对比（由Read View维护），如果DB_TRX_ID跟Read View的属性做了某些比较，不符合可见性，那就通过DB_ROLL_PTR回滚指针去取出Undo Log中的DB_TRX_ID再比较，即遍历链表的DB_TRX_ID（从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的DB_TRX_ID, 那么这个DB_TRX_ID所在的旧记录就是当前事务能看见的最新老版本 那么这个判断条件是什么呢？ 如上，它是一段MySQL判断可见性的一段源码，即changes_visible方法（不完全哈，但能看出大致逻辑），该方法展示了我们拿DB_TRX_ID去跟Read View某些属性进行怎么样的比较 在展示之前，我先简化一下Read View，我们可以把Read View简单的理解成有三个全局属性 trx_list（名字我随便取的）一个数值列表，用来维护Read View生成时刻系统正活跃的事务IDup_limit_id记录trx_list列表中事务ID最小的IDlow_limit_idReadView生成时刻系统尚未分配的下一个事务ID，也就是目前已出现过的事务ID的最大值+1 首先比较DB_TRX_ID &lt; up_limit_id, 如果小于，则当前事务能看到DB_TRX_ID 所在的记录，如果大于等于进入下一个判断 接下来判断 DB_TRX_ID 大于等于 low_limit_id , 如果大于等于则代表DB_TRX_ID 所在的记录在Read View生成后才出现的，那对当前事务肯定不可见，如果小于则进入下一个判断 判断DB_TRX_ID 是否在活跃事务之中，trx_list.contains(DB_TRX_ID)，如果在，则代表我Read View生成时刻，你这个事务还在活跃，还没有Commit，你修改的数据，我当前事务也是看不见的；如果不在，则说明，你这个事务在Read View生成之前就已经Commit了，你修改的结果，我当前事务是能看见的 整体流程 我们在了解了隐式字段，undo log， 以及Read View的概念之后，就可以来看看MVCC实现的整体流程是怎么样了 整体的流程是怎么样的呢？我们可以模拟一下 当事务2对某行数据执行了快照读，数据库为该行数据生成一个Read View读视图，假设当前事务ID为2，此时还有事务1和事务3在活跃中，事务4在事务2快照读前一刻提交更新了，所以Read View记录了系统当前活跃事务1，3的ID，维护在一个列表上，假设我们称为trx_list Read View不仅仅会通过一个列表trx_list来维护事务2执行快照读那刻系统正活跃的事务ID，还会有两个属性up_limit_id（记录trx_list列表中事务ID最小的ID），low_limit_id(记录trx_list列表中事务ID最大的ID，也有人说快照读那刻系统尚未分配的下一个事务ID也就是目前已出现过的事务ID的最大值+1，我更倾向于后者；所以在这里例子中up_limit_id就是1，low_limit_id就是4 + 1 = 5，trx_list集合的值是1,3，Read View如下图 我们的例子中，只有事务4修改过该行记录，并在事务2执行快照读前，就提交了事务，所以当前该行当前数据的undo log如下图所示；我们的事务2在快照读该行记录的时候，就会拿该行记录的DB_TRX_ID去跟up_limit_id,low_limit_id和活跃事务ID列表(trx_list)进行比较，判断当前事务2能看到该记录的版本是哪个。 所以先拿该记录DB_TRX_ID字段记录的事务ID 4去跟Read View的的up_limit_id比较，看4是否小于up_limit_id(1)，所以不符合条件，继续判断 4 是否大于等于 low_limit_id(5)，也不符合条件，最后判断4是否处于trx_list中的活跃事务, 最后发现事务ID为4的事务不在当前活跃事务列表中, 符合可见性条件，所以事务4修改后提交的最新结果对事务2快照读时是可见的，所以事务2能读到的最新数据记录是事务4所提交的版本，而事务4提交的版本也是全局角度上最新的版本 也正是Read View生成时机的不同，从而造成RC,RR级别下快照读的结果的不同 MVCC相关问题RR是如何在RC级的基础上解决不可重复读的？ 当前读和快照读在RR级别下的区别： 表1: 表2: 而在表2这里的顺序中，事务B在事务A提交后的快照读和当前读都是实时的新数据400，这是为什么呢？ 这里与上表的唯一区别仅仅是表1的事务B在事务A修改金额前快照读过一次金额数据，而表2的事务B在事务A修改金额前没有进行过快照读。所以我们知道事务中快照读的结果是非常依赖该事务首次出现快照读的地方，即某个事务中首次出现快照读的地方非常关键，它有决定该事务后续快照读结果的能力 我们这里测试的是更新，同时删除和更新也是一样的，如果事务B的快照读是在事务A操作之后进行的，事务B的快照读也是能读取到最新的数据的 RC,RR级别下的InnoDB快照读有什么不同？ 正是Read View生成时机的不同，从而造成RC,RR级别下快照读的结果的不同 在RR级别下的某个事务的对某条记录的第一次快照读会创建一个快照及Read View, 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的是同一个Read View，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个Read View，所以对之后的修改不可见； 即RR级别下，快照读生成Read View时，Read View会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的。而早于Read View创建的事务所做的修改均是可见 而在RC级别下的，事务中，每次快照读都会新生成一个快照和Read View, 这就是我们在RC级别下的事务中可以看到别的事务提交的更新的原因 总之在RC隔离级别下，是每个快照读都会生成并获取最新的Read View；而在RR隔离级别下，则是同一个事务中的第一个快照读才会创建Read View, 之后的快照读获取的都是同一个Read View。","categories":[{"name":"面试","slug":"面试","permalink":"https://hutaozhang.github.io/categories/%E9%9D%A2%E8%AF%95/"},{"name":"Database","slug":"面试/Database","permalink":"https://hutaozhang.github.io/categories/%E9%9D%A2%E8%AF%95/Database/"},{"name":"MySQL","slug":"面试/Database/MySQL","permalink":"https://hutaozhang.github.io/categories/%E9%9D%A2%E8%AF%95/Database/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://hutaozhang.github.io/tags/MySQL/"},{"name":"面试","slug":"面试","permalink":"https://hutaozhang.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"MVCC","slug":"MVCC","permalink":"https://hutaozhang.github.io/tags/MVCC/"}]},{"title":"面试 MySQL 索引","slug":"面试-MySQL索引","date":"2021-03-06T13:33:13.730Z","updated":"2021-03-07T10:08:12.376Z","comments":true,"path":"posts/43567.html","link":"","permalink":"https://hutaozhang.github.io/posts/43567.html","excerpt":"","text":"MySQL 索引问答索引是什么？有什么作用？ MySQL索引是什么？MySQL索引有什么作用？ 索引类似大学图书馆建书目索引，可以提高数据检索的效率，降低数据库的IO成本。MySQL官方文档说500~800w条记录左右性能开始逐渐下降，所以大数据量建立索引是非常有必要的。MySQL提供了Explain，用于显示SQL执行的详细信息，可以进行索引的优化。 导致SQL执行慢的原因 硬件问题。（如网速慢，内存不足，I / O 吞吐量小，磁盘空间满了等） 没有索引或索引失效。（一般在互联网公司，DBA会在半夜把表锁了，重新建立一遍索引，因为当你删除某个数据的时候，索引的树结构就不完整了。所以互联网公司的数据做的是假删除.一是为了做数据分析,二是为了不破坏索引） 数据过多。（官方文档说500W-800W条数据之后性能逐渐开始下降） 服务器调优及各个参数设置。（调整my.cnf） 如何解决这些问题呢？ 先观察，开启慢查询日志，设置相应的阈值（比如超过3秒就是慢SQL），在生产环境跑上个一天过后，看看哪些SQL比较慢。 Explain和慢SQL分析。比如SQL语句写的烂，索引没有或失效，关联查询太多（有时候是设计缺陷或者不得以的需求）等等。 Show Profile是比Explain更近一步的执行细节，可以查询到执行每一个SQL都干了什么事，这些事分别花了多少秒。 找DBA或者运维对MySQL进行服务器的参数调优。 什么是索引？MySQL官方对索引的定义为：索引(Index)是帮助MySQL高效获取数据的数据结构。我们可以简单理解为：快速查找排好序的一种数据结构。 Mysql索引主要有两种结构：B+Tree索引和Hash索引。我们平常所说的索引，如果没有特别指明，一般都是指B树结构组织的索引(B+Tree索引)。索引如图所示： 最外层浅蓝色磁盘块1里有数据17、35（深蓝色）和指针P1、P2、P3（黄色）。P1指针表示小于17的磁盘块，P2是在17-35之间，P3指向大于35的磁盘块。真实数据存在于子叶节点也就是最底下的一层3、5、9、10、13…非叶子节点不存储真实的数据，只存储指引搜索方向的数据项，如17、35。 查找过程：例如搜索28数据项，首先加载磁盘块1到内存中，发生一次I/O，用二分查找确定在P2指针。接着发现28在26和30之间，通过P2指针的地址加载磁盘块3到内存，发生第二次I/O。用同样的方式找到磁盘块8，发生第三次I/O。真实的情况是，上面3层的B+Tree可以表示上百万的数据，上百万的数据只发生了三次I/O而不是上百万次I/O，时间提升是巨大的。 那我们在什么情况下该创建索引呢？索引虽然能非常高效的提高查询速度，同时却会降低更新表的速度。实际上索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录，所以索引列也是要占用空间的。","categories":[{"name":"面试","slug":"面试","permalink":"https://hutaozhang.github.io/categories/%E9%9D%A2%E8%AF%95/"},{"name":"MySQL","slug":"面试/MySQL","permalink":"https://hutaozhang.github.io/categories/%E9%9D%A2%E8%AF%95/MySQL/"}],"tags":[{"name":"索引","slug":"索引","permalink":"https://hutaozhang.github.io/tags/%E7%B4%A2%E5%BC%95/"},{"name":"Index","slug":"Index","permalink":"https://hutaozhang.github.io/tags/Index/"},{"name":"MySQL","slug":"MySQL","permalink":"https://hutaozhang.github.io/tags/MySQL/"},{"name":"面试","slug":"面试","permalink":"https://hutaozhang.github.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"面试 MySQL 事务","slug":"面试-MySQL事务","date":"2021-03-06T13:14:51.911Z","updated":"2021-03-07T09:10:52.985Z","comments":true,"path":"posts/29528.html","link":"","permalink":"https://hutaozhang.github.io/posts/29528.html","excerpt":"","text":"问题一：Mysql事务简介问题二：ACID简介问题三：ACID原理问题四：事务隔离级别问题五：Mysql的锁机制问题六：事务底层实现原理问题一：Mysql事务简介问题二：ACID简介问题三：ACID原理问题四：事务隔离级别问题五：Mysql的锁机制问题六：事务底层实现原理","categories":[{"name":"面试","slug":"面试","permalink":"https://hutaozhang.github.io/categories/%E9%9D%A2%E8%AF%95/"},{"name":"Database","slug":"面试/Database","permalink":"https://hutaozhang.github.io/categories/%E9%9D%A2%E8%AF%95/Database/"},{"name":"MySQL","slug":"面试/Database/MySQL","permalink":"https://hutaozhang.github.io/categories/%E9%9D%A2%E8%AF%95/Database/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://hutaozhang.github.io/tags/MySQL/"},{"name":"面试","slug":"面试","permalink":"https://hutaozhang.github.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Database 事务ACID特性","slug":"Database事务ACID特性","date":"2021-03-06T09:52:38.367Z","updated":"2021-03-07T10:05:41.474Z","comments":true,"path":"posts/45033.html","link":"","permalink":"https://hutaozhang.github.io/posts/45033.html","excerpt":"","text":"事务的ACID特性 原子性(Atomicity): 事务中的所有操作作为一个整体像原子一样不可分割，要么全部成功,要么全部失败。 一致性(Consistency): 事务的执行结果必须使数据库从一个一致性状态到另一个一致性状态。一致性状态是指:1.系统的状态满足数据的完整性约束(主码,参照完整性,check约束等) 2.系统的状态反应数据库本应描述的现实世界的真实状态,比如转账前后两个账户的金额总和应该保持不变。 隔离性(Isolation): 并发执行的事务不会相互影响,其对数据库的影响和它们串行执行时一样。比如多个用户同时往一个账户转账,最后账户的结果应该和他们按先后次序转账的结果一样。 持久性(Durability): 事务一旦提交,其对数据库的更新就是持久的。任何事务或系统故障都不会导致数据丢失。 实现原理在事务的ACID特性中,C即一致性是事务的根本追求,而对数据一致性的破坏主要来自两个方面： 事务的并发执行 事务故障或系统故障 数据库系统是通过并发控制技术和日志恢复技术来避免这种情况发生的。并发控制技术保证了事务的隔离性,使数据库的一致性状态不会因为并发执行的操作被破坏。日志恢复技术保证了事务的原子性,使一致性状态不会因事务或系统故障被破坏。同时使已提交的对数据库的修改不会因系统崩溃而丢失,保证了事务的持久性。 事务特性–隔离性并发异常 脏读脏读是指一个事务读取了另一个事务未提交的数据。在事务1对A的处理过程中,事务2读取了A的值,但之后事务1回滚,导致事务2读取的A是未提交的脏数据。 例子： 领导给张三发工资，10000元已打到张三账户，但该事务还未提交，正好这时候张三去查询工资，发现10000元已到账。这时领导发现张三工资算多了5000元，于是回滚了事务，修改了金额后将事务提交。最后张三实际到账的只有5000元。 不可重复读一次事务发生了两次读操作，两个读操作之间发生了另一个事务对数据修改操作，这时候第一次和第二次读到的数据不一致。 不可重复度关注点在数据更新和删除，通过行级锁可以实现可重复读的隔离级别。 由于事务2对A的已提交修改,事务1前后两次读取的结果不一致。 例子： 张三需要转走1000元，系统读到卡余额有2000元，此时张三老婆正好需要转走2000元，并且在张三提交事务前把2000元转走了，当张三提交转账是系统提示余额不足。 幻读当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行。 相对于不可重复读，幻读更关注其它事务的新增数据。通过行级锁可以避免不可重复读，但无法解决幻读的问题，想要解决幻读，只能通过Serializable隔离级别来实现。 事务1查询A&lt;5的数据,由于事务2插入了一条A=4的数据,导致事务1两次查询得到的结果不一样 例子： 张三老婆准备打印张三这个月的信用卡消费记录，经查询发现消费了两次共1000元，而这时张三刚按摩完准备结账，消费了1000元，这时银行记录新增了一条1000元的消费记录。当张三老婆将消费记录打印出来时，发现总额变为了2000元，这让张三老婆很诧异。 串行化读Serializable是最高的隔离级别，性能很低，一般很少用。在这级别下，事务是串行顺序执行的，不仅避免了脏读、不可重复读，还避免了幻读。 丢失更新丢失更新是指事务覆盖了其他事务对数据的已提交修改,导致这些修改好像丢失了一样。 脏写脏写是指事务回滚了其他事务对数据项的已提交修改。 所有事务隔离级别都不允许出现脏写 事务隔离级别 隔离级别 隔离级别的值 导致的问题 Read uncommitted(读未提交) 0 脏读，不可重复读，幻读 Read committed(读已提交） 1 避免脏读，允许不可重复读和幻读 Repeatable(可重复读) 2 MySQL默认的隔离级别。避免脏读，不可重复读，允许幻读 Serializable(串行化) 3 串行化读，事务只能一个一个执行，避免了 脏读、不可重复读、幻读。执行效率慢，使用时慎重 事务隔离实现–并发控制 并发控制技术是实现事务隔离性以及不同隔离级别的关键,实现方式有很多,按照其对可能冲突的操作采取的不同策略可以分为乐观并发控制和悲观并发控制两大类。 乐观并发控制: 对于并发执行可能冲突的操作,假定其不会真的冲突,允许并发执行,直到真正发生冲突时才去解决冲突,比如让事务回滚。 快照隔离 有效性检查 悲观并发控制: 对于并发执行可能冲突的操作,假定其必定发生冲突,通过让事务等待(锁)或者中止(时间戳排序)的方式使并行的操作串行执行。 封锁 时间戳排序 数据库故障与故障恢复故障种类 数据库运行过程中可能会出现故障,这些故障包括事务故障和系统故障两大类 事务故障:比如非法输入,系统出现死锁,导致事务无法继续执行。 系统故障:比如由于软件漏洞或硬件错误导致系统崩溃或中止。 这些故障可能会对事务和数据库状态造成破坏,因而必须提供一种技术来对各种故障进行恢复,保证数据库一致性,事务的原子性以及持久性。数据库通常以日志的方式记录数据库的操作从而在故障时进行恢复,因而可以称之为日志恢复技术。 事务故障 事务的执行过程可以简化如下: 系统会为每个事务开辟一个私有工作区 事务读操作将从磁盘中拷贝数据项到工作区中,在执行写操作前所有的更新都作用于工作区中的拷贝. 事务的写操作将把数据输出到内存的缓冲区中,等到合适的时间再由缓冲区管理器将数据写入到磁盘。 由于数据库存在立即修改和延迟修改,所以在事务执行过程中可能存在以下情况: 在事务提交前出现故障,但是事务对数据库的部分修改已经写入磁盘数据库中。这导致了事务的原子性被破坏。 在系统崩溃前事务已经提交,但数据还在内存缓冲区中,没有写入磁盘。系统恢复时将丢失此次已提交的修改。这是对事务持久性的破坏。 日志种类和格式 &lt;T,X,V1,V2&gt;:描述一次数据库写操作,T是执行写操作的事务的唯一标识,X是要写的数据项,V1是数据项的旧值,V2是数据项的新值。 &lt;T,X,V1&gt;:对数据库写操作的撤销操作,将事务T的X数据项恢复为旧值V1。在事务恢复阶段插入。 &lt;T start&gt;: 事务T开始 &lt;T commit&gt;: 事务T提交 &lt;T abort&gt;: 事务T中止 关于日志,有以下两条规则 系统在对数据库进行修改前会在日志文件末尾追加相应的日志记录。 当一个事务的commit日志记录写入到磁盘成功后,称这个事务已提交,但事务所做的修改可能并未写入磁盘 日志恢复的核心思想 撤销事务undo:将事务更新的所有数据项恢复为日志中的旧值,事务撤销完毕时将插入一条&lt;T abort&gt;记录。 重做事务redo:将事务更新的所有数据项恢复为日志中的新值。 事务正常回滚/因事务故障中止将进行redo。系统从崩溃中恢复时将先进行redo再进行undo。 以下事务将进行undo:日志中只包括&lt;T start&gt;记录,但既不包括&lt;T commit&gt;记录也不包括&lt;T abort&gt;记录.以下事务将进行redo:日志中包括&lt;T start&gt;记录,也包括&lt;T commit&gt;记录或&lt;T abort&gt;记录。 假设系统从崩溃中恢复时日志记录如下 123456&lt;T0 start&gt;&lt;T0,A,1000,950&gt;&lt;T0,B,2000,2050&gt;&lt;T0 commit&gt;&lt;T1 start&gt;&lt;T1,C,700,600&gt; 由于T0既有start记录又有commit记录,将会对事务T0进行重做,执行相应的redo操作。由于T1只有start记录,将会对T1进行撤销,执行相应的undo操作,撤销完毕将写入一条abort记录。 事务故障中止/正常回滚的恢复流程 从后往前扫描日志,对于事务T的每个形如&lt;T,X,V1,V2&gt;的记录,将旧值V1写入数据项X中。 往日志中写一个特殊的只读记录&lt;T,X,V1&gt;,表示将数据项恢复成旧值V1,这是一个只读的补偿记录,不需要根据它进行undo。 一旦发现了&lt;T start&gt;日志记录,就停止继续扫描,并往日志中写一个&lt;T abort&gt;日志记录。 系统崩溃时的恢复过程(带检查点) 检查点是形如&lt;checkpoint L&gt;的特殊的日志记录,L是写入检查点记录时还未提交的事务的集合,系统保证在检查点之前已经提交的事务对数据库的修改已经写入磁盘,不需要进行redo。检查点可以加快恢复的过程。 系统奔溃时的恢复过程分为两个阶段:重做阶段和撤销阶段。 重做阶段: 系统从最后一个检查点开始正向的扫描日志,将要重做的事务的列表undo-list设置为检查点日志记录中的L列表。 发现&lt;T,X,V1,V2&gt;的更新记录或&lt;T,X,V&gt;的补偿撤销记录,就重做该操作。 发现&lt;T start&gt;记录,就把T加入到undo-list中。 发现&lt;T abort&gt;或&lt;T commit&gt;记录,就把T从undo-list中去除。 撤销阶段: 系统从尾部开始反向扫描日志 发现属于undo-list中的事务的日志记录,就执行undo操作 发现undo-list中事务的T的&lt;T start&gt;记录,就写入一条&lt;T abort&gt;记录,并把T从undo-list中去除。 undo-list为空,则撤销阶段结束 总结:先将日志记录中所有事务的更新按顺序重做一遍,在针对需要撤销的事务按相反的顺序执行其更新操作的撤销操作。 一个系统崩溃恢复的例子恢复前的日志如下,写入最后一条日志记录后系统崩溃 1234567891011 &lt;T0 start&gt;&lt;T0,B,2000,2050&gt;&lt;T2 commit&gt;&lt;T1 start&gt;&lt;checkpoint &#123;T0,T1&#125;&gt; &#x2F;&#x2F;之前T2已经commit,故不用重做&lt;T1,C,700,600&gt;&lt;T1 commit&gt;&lt;T2 start&gt;&lt;T2,A,500,400&gt;&lt;T0,B,2000&gt;&lt;T0 abort&gt; &#x2F;&#x2F;T0回滚完成,插入该记录后系统崩溃","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"Database","slug":"教程/Database","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Database/"}],"tags":[{"name":"Database","slug":"Database","permalink":"https://hutaozhang.github.io/tags/Database/"},{"name":"事务","slug":"事务","permalink":"https://hutaozhang.github.io/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"Transaction","slug":"Transaction","permalink":"https://hutaozhang.github.io/tags/Transaction/"},{"name":"ACID","slug":"ACID","permalink":"https://hutaozhang.github.io/tags/ACID/"}]},{"title":"Database 事务","slug":"Database事务","date":"2021-03-06T08:32:28.543Z","updated":"2021-03-07T10:07:20.193Z","comments":true,"path":"posts/46219.html","link":"","permalink":"https://hutaozhang.github.io/posts/46219.html","excerpt":"","text":"一、 数据库事务数据库事务定义数据库事务(transaction)是访问并可能操作各种数据项的一个数据库操作序列，这些操作要么全部执行,要么全部不执行，是一个不可分割的工作单位。事务由事务开始与事务结束之间执行的全部数据库操作组成。 解析： Transaction 事务就是一段sql 语句的批处理，但是这个批处理是一个atom（原子），不可分割，要么都执行，要么回滚（rollback）都不执行。 一个完整的业务需要批量的DML(insert、update、delete)语句共同联合完成 事务只和DML语句有关，或者说DML语句才有事务。这个和业务逻辑有关，业务逻辑不同，DML语句的个数不同 事务应用：在数据库系统中，事务是工作的离散单位，它可以是修改一个用户的账户余额，可以是库存项的写操作，也可以是一个用户的删除。 在单用户、单数据库环境下执行事务比较简单，但在分布式环境下，维护多个数据库的完整性就比较复杂。 大多数联机事务处理系统是在大型计算机上实现的，这是由于它的操作复杂，需要快速的输入/输出和完善的管理。 如果一个事务在多个场地进行修改，那就需要管理机制来防止数据重写并提供同步。 另外还需要具有返回失效事务的能力，提供安全保障和提供数据恢复能力。 数据库事务是一个逻辑上的划分，有的时候并不是很明显，它可以是一个操作步骤也可以是多个操作步骤。我们可以这样理解数据库事物:对数据库所做的一系列修改，在修改过程中，暂时不写入数据库，而是缓存起来，用户在自己的终端可以预览变化，直到全部修改完成，并经过检查确认无误后，一次性提交并写入数据库，在提交之前，必要的话所做的修改都可以取消。提交之后，就不能撤销，提交成功后其他用户才可以通过查询浏览数据的变化。 事务优点以事务的方式对数据库进行访问，有如下的优点：1、 把逻辑相关的操作分成了一个组；2、 在数据永久改变前，可以预览数据变化；3、 能够保证数据的读一致性 经典案例事例1. 银行转账 从第一个账户划出款项 将款项存入第二个账户 解析：在这个过程中，两个环节是关联的。第一个账户划出款项必须保证正确的存入第二个账户，如果第二个环节没有完成，整个的过程都应该取消，否则就会发生丢失款项的问题。整个交易过程，可以看作是一个事物，成功则全部成功，失败则需要全部撤消，这样可以避免当操作的中间环节出现问题时，产生数据不一致的问题。 二、 事务四大特性：ACIDAtomicity（原子性）一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 Consistency（一致性）在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 Isolation（隔离性）数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别: 读未提交（Read uncommitted） 其它事务未提交就可以读 读提交（read committed） 其它事务只有提交了才能读 可重复读（repeatable read） 只管自己启动事务时候的状态,不受其它事务的影响(mysql默认) 串行化（Serializable） 按照顺序提交事务保证了数据的安全性,但无法实现并发 在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。 Durability（持久性）事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 三、 事务使用事务的术语开启事务：Start Transaction事务结束：End Transaction提交事务：Commit Transaction回滚事务：Rollback Transaction 事务控制语句 BEGIN 或 START TRANSACTION 显式地开启一个事务； COMMIT 也可以使用 COMMIT WORK，不过二者是等价的。COMMIT 会提交事务，并使已对数据库进行的所有修改成为永久性的； ROLLBACK 也可以使用 ROLLBACK WORK，不过二者是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改； SAVEPOINT identifier，SAVEPOINT 允许在事务中创建一个保存点，一个事务中可以有多个 SAVEPOINT； RELEASE SAVEPOINT identifier 删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常； ROLLBACK TO identifier 把事务回滚到标记点； SET TRANSACTION 用来设置事务的隔离级别。InnoDB 存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ 和 SERIALIZABLE。 事务开启和结束的标志开启标志 任何一条DML语句(insert、update、delete)执行，标志事务的开启 结束标志 提交：成功的结束，将所有的DML语句操作历史记录和底层硬盘数据来一次同步 回滚：失败的结束，将所有的DML语句操作历史记录全部清空 事务与数据库底层数据在事物进行过程中，未结束之前，DML语句是不会更改底层数据，只是将历史操作记录一下，在内存中完成记录。只有在事物结束的时候，而且是成功的结束的时候，才会修改底层硬盘文件中的数据","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"Database","slug":"教程/Database","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Database/"}],"tags":[{"name":"Database","slug":"Database","permalink":"https://hutaozhang.github.io/tags/Database/"},{"name":"事务","slug":"事务","permalink":"https://hutaozhang.github.io/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"Transaction","slug":"Transaction","permalink":"https://hutaozhang.github.io/tags/Transaction/"}]},{"title":"GitHub","slug":"GitHub","date":"2021-02-24T17:51:10.885Z","updated":"2021-02-24T18:35:36.080Z","comments":true,"path":"posts/57711.html","link":"","permalink":"https://hutaozhang.github.io/posts/57711.html","excerpt":"","text":"注册 Github 账户 GitHub官网点击此处 ，点击 Sign Up 注册账户 创建项目代码库 页面左侧 Repository 点击按钮New步骤及注意事项见下图： Git 免密登陆 右键，Git Bash1$ ls -al ~&#x2F;.ssh 如果没有，执行下一步。 新建 SSH Key1$ ssh-keygen -t rsa -C &quot;your email@example.com&quot; 接下来，一路enter到底。1234Enter file in which to save the key(&#x2F;c&#x2F;Users&#x2F;uestc&#x2F;.ssh&#x2F;id_rsa):Enter passphrase(empty for no passphrase)Your identification has been saved in &#x2F;c&#x2F;User&#x2F;uestc&#x2F;.ssh&#x2F;id_rsa.Your public key has been saved in &#x2F;c&#x2F;Users&#x2F;uestc&#x2F;.ssh&#x2F;id_rsa.pub. 将id_rsa.pub公钥中的内容添加到Git仓库设置中 进入目录C:\\Users\\uestc.ssh，打开id_rsa.pub文件，并复制其中的所有内容 登录GitHub 点击右上角的头像 ，然后点击settings 选择SSH and GPG keys New SSH key 测试1$ ssh -T git@github.com 配置本地个人信息Git 会根据用户的名字和邮箱来记录提交，GitHub 也是用这些信息来做权限的处理，输入以下命令进行个人信息的设置，把名称和邮箱替换成你自己的，名字可以不是 GitHub 的昵称，但为了方便记忆，建议与 GitHub 一致 12$ git config --global user.name &quot;此处填你的用户名&quot; $ git config --global user.email &quot;此处填你的邮箱&quot;","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"GitHub","slug":"教程/GitHub","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/GitHub/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://hutaozhang.github.io/tags/Git/"},{"name":"GitHub","slug":"GitHub","permalink":"https://hutaozhang.github.io/tags/GitHub/"}]},{"title":"Blog搭建","slug":"Blog搭建","date":"2021-02-24T17:51:10.883Z","updated":"2021-02-24T18:33:19.371Z","comments":true,"path":"posts/2.html","link":"","permalink":"https://hutaozhang.github.io/posts/2.html","excerpt":"","text":"前言 HexoHexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 GitHub PagesGithub Pages允许用户的任何一个Repo的gh-pages分支上的代码可以经由HTTP访问到。类似提供了静态文件服务。 搭建私人Git仓库Git是一个分布式版本控制软件，不仅能在服务器上实现版本控制，也能独立使用。虽然现在Github私有库全面开放，但是有些私密的小项目放在Github的服务器上总有些不安心。这里我们使用私人仓库是因为github pages提供的静态文件服务带宽低，经常卡顿。 环境安装 Git 安装如果准备白嫖，只需安装本地Git即可。安装方法： Git安装 Node 安装安装地址：点击此处 Hexo 安装 检查环境123$ git --version$ node -v$ npm -v 注意：npm -v 不起作用，请先执行npm install 安装 Hexo 创建本地Blog仓库：D:\\workspace\\Blog1$ npm install hexo-cli -g 初始化Hexo1$ hexo init 测试Hexo服务1$ hexo server 测试连接：http://localhost:4000/ GitHub Pages 部署博客 创建GitHub仓库：详情参考: GitHub 登录 Github 打开自己的项目 your name.github.io 鼠标移到 Clone or download 按钮，选择 Use SSH 复制地址 打开_config.yml 文件（D:\\workspace\\Blog_config.yml）配置信息 将本地仓库推送到远程仓库Hexo安装git插件1npm install hexo-deployer-git --save 编译部署12$ hexo g$ hexo d 或者直接 hexo g d","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"Blog","slug":"教程/Blog","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Blog/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://hutaozhang.github.io/tags/Hexo/"}]},{"title":"Hexo优化之永久链接","slug":"Hexo优化之永久链接","date":"2021-02-24T17:51:10.881Z","updated":"2021-02-24T18:34:40.551Z","comments":true,"path":"posts/1.html","link":"","permalink":"https://hutaozhang.github.io/posts/1.html","excerpt":"","text":"前言Hexo默认的静态URL格式是 :year/:month/:day/:title，也就是按照年、月、日、标题来生成固定链接的。如http://xxx.yy.com/2020/07/06/hello-world 这种默认配置的缺点就是一般文件名是中文，导致url链接里有中文出现，这会造成很多问题，也不利于seo，另外就是年月日都会有分隔符。 知识点 info,百度蜘蛛抓取网页的规则: 对于蜘蛛说网页权重越高、信用度越高抓取越频繁，例如网站的首页和内页。蜘蛛先抓取网站的首页，因为首页权重更高，并且大部分的链接都是指向首页。然后通过首页抓取网站的内页，并不是所有内页蜘蛛都会去抓取。 success,搜索引擎认为对于一般的中小型站点，3层足够承受所有的内容了，所以蜘蛛经常抓取的内容是前三层，而超过三层的内容蜘蛛认为那些内容并不重要，所以不经常爬取。出于这个原因所以permalink后面跟着的最好不要超过2个斜杠。 使用 hexo-abbrlink 插件可以完美解决，具体使用方法如下： 安装npm包：1npm install hexo-abbrlink --save 修改_config.yml文件中的配置项（记得把原来的permalink:删除掉）:12345#设置永久链接permalink: posts&#x2F;:abbrlink.html # 此处可以自己设置，也可以直接使用 :&#x2F;abbrlinkabbrlink: alg: crc16 #算法： crc16(default) and crc32 rep: dec #进制： dec(default) and hex 关于插件设置Abbrlink插件拥有两项设置选项: alg: 算法(目前支持crc16和crc32算法，默认值是crc16) rep: 形式(生成的链接可以是十六进制格式也可以是十进制格式，默认值是十进制格式) 事例： 123456789crc16 &amp; hexhttps:&#x2F;&#x2F;www.heson10.com&#x2F;posts&#x2F;55c6.htmlcrc16 &amp; dechttps:&#x2F;&#x2F;www.heson10.com&#x2F;posts&#x2F;43212.html crc32 &amp; hexhttps:&#x2F;&#x2F;www.heson10.com&#x2F;posts&#x2F;6ec16a2c.htmlcrc32 &amp; dechttps:&#x2F;&#x2F;www.heson10.com&#x2F;posts&#x2F;1521457752.html","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"Blog","slug":"教程/Blog","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Blog/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://hutaozhang.github.io/tags/Hexo/"},{"name":"优化","slug":"优化","permalink":"https://hutaozhang.github.io/tags/%E4%BC%98%E5%8C%96/"}]},{"title":"Git常用命令","slug":"Git常见命令","date":"2021-02-03T01:27:43.759Z","updated":"2021-02-24T17:25:44.807Z","comments":true,"path":"posts/7065.html","link":"","permalink":"https://hutaozhang.github.io/posts/7065.html","excerpt":"","text":"Git常用命令一、本地操作：其它 git init：初始化本地库 git status：查看工作区、暂存区的状态 git add &lt;file name&gt;：将工作区的“新建/修改”添加到暂存区 git rm --cached &lt;file name&gt;：移除暂存区的修改 git commit &lt;file name&gt;：将暂存区的内容提交到本地库 tip：需要再编辑提交日志，比较麻烦，建议用下面带参数的提交方法 git commit -m &quot;提交日志&quot; &lt;file name&gt;：文件从暂存区到本地库 日志 git log：查看历史提交 tip：空格向下翻页，b向上翻页，q退出 git log --pretty=oneline：以漂亮的一行显示，包含全部哈希索引值 git log --oneline：以简洁的一行显示，包含简洁哈希索引值 git reflog：以简洁的一行显示，包含简洁哈希索引值，同时显示移动到某个历史版本所需的步数 版本控制 git reset --hard 简洁/完整哈希索引值：回到指定哈希值所对应的版本 git reset --hard HEAD：强制工作区、暂存区、本地库为当前HEAD指针所在的版本 git reset --hard HEAD^：后退一个版本 tip：一个^表示回退一个版本 git reset --hard HEAD~1：后退一个版本 tip：波浪线~后面的数字表示后退几个版本 比较差异 git diff：比较工作区和暂存区的所有文件差异 git diff &lt;file name&gt;：比较工作区和暂存区的指定文件的差异 git diff HEAD|HEAD^|HEAD~|哈希索引值 &lt;file name&gt;：比较工作区跟本地库的某个版本的指定文件的差异 分支操作 git branch -v：查看所有分支 git branch -d &lt;分支名&gt;：删除本地分支 git branch &lt;分支名&gt;：新建分支 git checkout &lt;分支名&gt;：切换分支 git merge &lt;被合并分支名&gt;：合并分支 tip：如master分支合并 hot_fix分支，那么当前必须处于master分支上，然后执行 git merge hot_fix 命令 tip2：合并出现冲突 ①删除git自动标记符号，如&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD、&gt;&gt;&gt;&gt;&gt;&gt;&gt;等 ②修改到满意后，保存退出 ③git add &lt;file name&gt; ④git commit -m &quot;日志信息&quot;，此时后面不要带文件名 二、本地库跟远程库交互：git clone &lt;远程库地址&gt;：克隆远程库 功能：①完整的克隆远程库为本地库，②为本地库新建origin别名，③初始化本地库 git remote -v：查看远程库地址别名 git remote add &lt;别名&gt; &lt;远程库地址&gt;：新建远程库地址别名 git remote rm &lt;别名&gt;：删除本地中远程库别名 git push &lt;别名&gt; &lt;分支名&gt;：本地库某个分支推送到远程库，分支必须指定 git pull &lt;别名&gt; &lt;分支名&gt;：把远程库的修改拉取到本地 tip：该命令包括git fetch，git merge git fetch &lt;远程库别名&gt; &lt;远程库分支名&gt;：抓取远程库的指定分支到本地，但没有合并 git merge &lt;远程库别名/远程库分支名&gt;：将抓取下来的远程的分支，跟当前所在分支进行合并 git fork：复制远程库 tip：一般是外面团队的开发人员fork本团队项目，然后进行开发，之后外面团队发起pull request，然后本团队进行审核，如无问题本团队进行merge（合并）到团队自己的远程库，整个流程就是本团队跟外面团队的协同开发流程，Linux的团队开发成员即为这种工作方式。 借用网上的图","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"Git","slug":"教程/Git","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://hutaozhang.github.io/tags/Git/"},{"name":"命令","slug":"命令","permalink":"https://hutaozhang.github.io/tags/%E5%91%BD%E4%BB%A4/"}]},{"title":"Git碰到的坑","slug":"Git碰到的坑","date":"2021-02-03T01:27:43.759Z","updated":"2021-02-24T17:25:44.810Z","comments":true,"path":"posts/7735.html","link":"","permalink":"https://hutaozhang.github.io/posts/7735.html","excerpt":"","text":"凡走过，必留下痕迹。才过的坑，印记更深！！！ Git 问题 问题：用户名密码正确，但是报错用户名密码错误 remote: Invalid username or password 方案: https://www.freesion.com/article/8250330335/ https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token error: RPC failed; curl 18 transfer closed with outstanding read data remaining fatal: The remote end hung up unexpectedly 方案： https://www.cnblogs.com/niudaben/p/12503650.html 这里http.postBuffer 5242880000 error: RPC failed; curl 56 OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 10054 方案： https://blog.csdn.net/lw545034502/article/details/90289437 问题：相同分支本地文件与GitHub不一致修改文件名大小写后重新提交代码，结果发现git status中并未找到该变化，究其原因是默认git配置了忽略大小写敏感 1234$ git status$ git config core.ignorecase true$ git config core.ignorecase false","categories":[{"name":"问题","slug":"问题","permalink":"https://hutaozhang.github.io/categories/%E9%97%AE%E9%A2%98/"},{"name":"Git","slug":"问题/Git","permalink":"https://hutaozhang.github.io/categories/%E9%97%AE%E9%A2%98/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://hutaozhang.github.io/tags/Git/"},{"name":"问题","slug":"问题","permalink":"https://hutaozhang.github.io/tags/%E9%97%AE%E9%A2%98/"}]},{"title":"Hexo 碰到的坑","slug":"Hexo碰到的坑","date":"2021-02-03T01:27:43.759Z","updated":"2021-02-24T17:25:44.813Z","comments":true,"path":"posts/45533.html","link":"","permalink":"https://hutaozhang.github.io/posts/45533.html","excerpt":"","text":"凡走过，必留下痕迹。才过的坑，印记更深！！！ Hexo 碰到的坑 box 文件夹下index.html找不到 123456 hexo new page box 将box的page拷贝过来 hexo d &#96;&#96;&#96; 2. 文件名修改，hexo d 推不上过去 Hexo 路径下&#96;deploy_git.git\\config&#96; 修改为 &#96;ignorecase &#x3D; false&#96; 检查文件名大小写 git config core.ignorecase 设置忽略大小写 git config core.ignorecase false 1233. 本地测试与public不一致 &#96;hexo s&#96; 生成页面与 &#96;hexo g&#96; 生成页面不一致 hexo clean hexo server #浏览器打开index.html页面代码 hexo g #public下index.htm页面代码不一致 两个index.html不一致改变方法 解决办法：强行修改ejs文件。 部署是分支不正确 Hexo 的配置文件_config.yml，已修改branch，但是不起作用 解决办法：修改github默认分支","categories":[{"name":"问题","slug":"问题","permalink":"https://hutaozhang.github.io/categories/%E9%97%AE%E9%A2%98/"},{"name":"Hexo","slug":"问题/Hexo","permalink":"https://hutaozhang.github.io/categories/%E9%97%AE%E9%A2%98/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://hutaozhang.github.io/tags/Hexo/"},{"name":"问题","slug":"问题","permalink":"https://hutaozhang.github.io/tags/%E9%97%AE%E9%A2%98/"}]},{"title":"Nginx 安装","slug":"Nginx安装","date":"2021-02-03T01:27:43.759Z","updated":"2021-02-24T17:25:44.821Z","comments":true,"path":"posts/63728.html","link":"","permalink":"https://hutaozhang.github.io/posts/63728.html","excerpt":"","text":"Docker 安装 Nginx检查镜像docker search nginx root@JD:~# docker search nginx NAME DESCRIPTION STARS OFFICIAL AUTOMATED nginx Official build of Nginx. 14373 [OK] 拉取镜像docker pull nginx人懒，直接选官方的了。 查看镜像docker images nginx root@JD:~# docker images nginx REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest f6d0b4767a6c 3 weeks ago 133MB 启动一个简单 ngix 容器 启动docker run --name nginx-test -p 8081:80 -d nginx –name nginx容器名 -p 端口，容器端口80，映射到本机端口8081 -d 后台运行 检测容器是否运行docker ps root@JD:~# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4dbe23a3c86d nginx &quot;/docker-entrypoint.…&quot; About an hour ago Up About an hour 80/tcp, 0.0.0.0:8081-&gt;8081/tcp nginx-blog 查看运行效果命令行：curl 127.0.0.1:8081浏览器：localhost:8081 Nginx 高级配置挂载 创建挂载目录mkdir -p /root/nginx/&#123;conf,conf.d,logs,html&#125; /root/nginx/logs 目录将映射为 nginx 容器的日志目录 `/root/nginx/conf` 目录里的配置文件将映射为 nginx 容器的配置文件 `/root/nginx/conf.d`目录里的配置文件将映射为 nginx服务所需配置 `/root/nginx/html` 目录里的文件将映射为将要运行的项目 注意： 这里我搭配Git使用，详情参考： Git安装 配置文件聪明人（懒汉）：借用刚才启动简单实例的配置文件 cp /etc/nginx/nginx.conf /root/nginx/conf/ cp /etc/nginx/conf.d/default.conf /root/nginx/conf.d/default.conf 老实人： vim /root/nginx/conf/nginx.conf123456789101112131415161718192021222324252627user nginx;worker_processes 1;error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log warn;pid &#x2F;var&#x2F;run&#x2F;nginx.pid;events &#123;worker_connections 1024;&#125;http &#123;include &#x2F;etc&#x2F;nginx&#x2F;mime.types;default_type application&#x2F;octet-stream;log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;&#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;&#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log main;sendfile on;#tcp_nopush on;keepalive_timeout 65;#gzip on;include &#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;*.conf;&#125; vim /root/nginx/conf.d/default.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748server &#123;listen 8081;server_name localhost;#charset koi8-r;#access_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;log&#x2F;host.access.log main;location &#x2F; &#123;root &#x2F;data&#x2F;nginx&#x2F;html;# root &#x2F;usr&#x2F;nginx&#x2F;html;index index.html index.htm;autoindex on;try_files $uri &#x2F;index&#x2F;index&#x2F;page.html;#try_files $uri &#x2F;index&#x2F;map&#x2F;page.html;&#125;#error_page 404 &#x2F;404.html;# redirect server error pages to the static page &#x2F;50x.html#error_page 500 502 503 504 &#x2F;50x.html;location &#x3D; &#x2F;50x.html &#123;root &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html;&#125;# proxy the PHP scripts to Apache listening on 127.0.0.1:80##location ~ \\.php$ &#123;# proxy_pass http:&#x2F;&#x2F;127.0.0.1;#&#125;# pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000##location ~ \\.php$ &#123;# root html;# fastcgi_pass 127.0.0.1:9000;# fastcgi_index index.php;# fastcgi_param SCRIPT_FILENAME &#x2F;scripts$fastcgi_script_name;# include fastcgi_params;#&#125;# deny access to .htaccess files, if Apache&#39;s document root# concurs with nginx&#39;s one##location ~ &#x2F;\\.ht &#123;# deny all;#&#125;&#125; 部署命令 12345docker run -d -p 8081:8081 --name nginx-blog \\-v &#x2F;home&#x2F;git&#x2F;project&#x2F;blog:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html \\-v &#x2F;root&#x2F;nginx&#x2F;conf&#x2F;nginx.conf:&#x2F;etc&#x2F;nginx&#x2F;nginx.conf \\-v &#x2F;root&#x2F;nginx&#x2F;conf.d&#x2F;default.conf:&#x2F;etc&#x2F;nginx&#x2F;conf.d&#x2F;default.conf \\-v &#x2F;root&#x2F;nginx&#x2F;logs:&#x2F;var&#x2F;log&#x2F;nginx nginx -v /home/git/project/blog:/usr/share/nginx/html blog文件用于存放项目文件-v /root/nginx/conf/nginx.conf:/etc/nginx/nginx.conf-v /root/nginx/conf.d/default.conf:/etc/nginx/conf.d/default.conf-v /root/nginx/logs:/var/log/nginx 运行检查： curl localhost:8081 #localhost不行用127.0.0.1 服务器ip:8081","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"Ninx","slug":"教程/Ninx","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Ninx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://hutaozhang.github.io/tags/Nginx/"},{"name":"Docker","slug":"Docker","permalink":"https://hutaozhang.github.io/tags/Docker/"}]},{"title":"Git安装","slug":"Git安装","date":"2021-02-03T01:27:43.744Z","updated":"2021-02-24T17:25:44.801Z","comments":true,"path":"posts/24585.html","link":"","permalink":"https://hutaozhang.github.io/posts/24585.html","excerpt":"","text":"Git 安装本地安装 Git待补充 服务器安装 Git 安装 GitDebian或Ubuntu：apt-get install gitCentOS：yum install -y git安装完成，看版本：git --version Git 使用 添加用户信息useradd usernamepasswd password实例： 12345useradd git -m passwd gitsu gitcd &#x2F;home&#x2F;gitmkdir -p projec&#x2F;blog -m 会在home下创建一个对应文件夹 su git 安全考虑切换git用户创建文件 初始化仓库并设置hooks 1234567mkdir repository &amp;&amp; cd repositorygit init --bare blog.git &#x2F;&#x2F; 创建一个干净的仓库cd blog.git&#x2F;hooks 切换到当前目录下vi post-receive &#x2F;&#x2F; 创建 hook 钩子函数，输入了内容如下:#!&#x2F;bin&#x2F;shgit --work-tree&#x3D;&#x2F;home&#x2F;git&#x2F;project&#x2F;blog --git-dir&#x3D;&#x2F;home&#x2F;git&#x2F;repository&#x2F;blog.git checkout -f 设置权限 123chmod +x post-receiveexit &#x2F;&#x2F; 退出到 root 登录 或者 su rootchown -R git:git &#x2F;home&#x2F;git&#x2F;repository&#x2F;blog.git &#x2F;&#x2F; 添加权限 出于安全考虑，禁用shell登录 12vi &#x2F;etc&#x2F;passwdgit:x:503:503::&#x2F;home&#x2F;git:&#x2F;bin&#x2F;bash 修改为：git:x:503:503::/home/git:/bin/git-shell或者git:x:1000:1000::/home/git: 本地测试Git Bash窗口下:默认：git clone git@192.168.1.11:/home/git/repository/blog.git修改了git默认端口：git clone git@192.168.1.11:6666/home/git/repository/blog.git git 替换成自己的用户名 @ 后面替换成自己的ip地址 ： 后面跟的是你的SSH端口号 端口号后面是你的目录 目录后面是你的.git文件 在blog目录下新建一个文件 test.txt 这是一个测试文件 123git add .git commit -m &quot;测试私人git仓库&quot;git push 服务器：hooks 会将文件存放到指定目录下 12cd &#x2F;home&#x2F;git&#x2F;project&#x2F;blog #切换到目标路径ls -l #这里应该能够看到test.txt文件","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"Git","slug":"教程/Git","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://hutaozhang.github.io/tags/Git/"},{"name":"服务器","slug":"服务器","permalink":"https://hutaozhang.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"Linux常用命令大全","slug":"Linux-命令","date":"2021-01-28T14:14:26.747Z","updated":"2021-02-24T17:25:44.825Z","comments":true,"path":"posts/23662.html","link":"","permalink":"https://hutaozhang.github.io/posts/23662.html","excerpt":"","text":"系统信息arch 显示机器的处理器架构uname -m 显示机器的处理器架构uname -r 显示正在使用的内核版本dmidecode -q 显示硬件系统部件 - (SMBIOS / DMI)hdparm -i /dev/hda 罗列一个磁盘的架构特性hdparm -tT /dev/sda 在磁盘上执行测试性读取操作cat /proc/cpuinfo 显示CPU info的信息cat /proc/interrupts 显示中断cat /proc/meminfo 校验内存使用cat /proc/swaps 显示哪些swap被使用cat /proc/version 显示内核的版本cat /proc/net/dev 显示网络适配器及统计cat /proc/mounts 显示已加载的文件系统lspci -tv 罗列 PCI 设备lsusb -tv 显示 USB 设备date 显示系统日期cal 2007 显示2007年的日历表date 041217002007.00 设置日期和时间 - 月日时分年.秒clock -w 将时间修改保存到 BIOS 关机 (系统的关机、重启以及登出 )shutdown -h now 关闭系统init 0 关闭系统telinit 0 关闭系统shutdown -h hours:minutes &amp; 按预定时间关闭系统shutdown -c 取消按预定时间关闭系统shutdown -r now 重启reboot 重启logout 注销 文件和目录cd /home 进入 ‘/ home’ 目录’cd .. 返回上一级目录cd ../.. 返回上两级目录cd 进入个人的主目录cd ~user1 进入个人的主目录cd - 返回上次所在的目录pwd 显示工作路径ls 查看目录中的文件ls -F 查看目录中的文件ls -l 显示文件和目录的详细资料ls -a 显示隐藏文件ls [0-9] 显示包含数字的文件名和目录名tree 显示文件和目录由根目录开始的树形结构lstree 显示文件和目录由根目录开始的树形结构mkdir dir1 创建一个叫做 ‘dir1’ 的目录’mkdir dir1 dir2 同时创建两个目录mkdir -p /tmp/dir1/dir2 创建一个目录树rm -f file1 删除一个叫做 ‘file1’ 的文件’rmdir dir1 删除一个叫做 ‘dir1’ 的目录’rm -rf dir1 删除一个叫做 ‘dir1’ 的目录并同时删除其内容rm -rf dir1 dir2 同时删除两个目录及它们的内容mv dir1 new_dir 重命名/移动 一个目录cp file1 file2 复制一个文件cp dir/* . 复制一个目录下的所有文件到当前工作目录cp -a /tmp/dir1 . 复制一个目录到当前工作目录cp -a dir1 dir2 复制一个目录 cp -r dir1 dir2 复制一个目录及子目录ln -s file1 lnk1 创建一个指向文件或目录的软链接ln file1 lnk1 创建一个指向文件或目录的物理链接touch -t 0712250000 file1 修改一个文件或目录的时间戳 - (YYMMDDhhmm)file file1 outputs the mime type of the file as texticonv -l 列出已知的编码iconv -f fromEncoding -t toEncoding inputFile &gt; outputFile creates a new from the given input file by assuming it is encoded in fromEncoding and converting it to toEncoding.find . -maxdepth 1 -name *.jpg -print -exec convert “{}” -resize 80x60 “thumbs/{}” ; batch resize files in the current directory and send them to a thumbnails directory (requires convert from Imagemagick) 文件搜索find / -name file1 从 ‘/‘ 开始进入根文件系统搜索文件和目录find / -user user1 搜索属于用户 ‘user1’ 的文件和目录find /home/user1 -name *.bin 在目录 ‘/ home/user1’ 中搜索带有’.bin’ 结尾的文件find /usr/bin -type f -atime +100 搜索在过去100天内未被使用过的执行文件find /usr/bin -type f -mtime -10 搜索在10天内被创建或者修改过的文件find / -name *.rpm -exec chmod 755 ‘{}’ ; 搜索以 ‘.rpm’ 结尾的文件并定义其权限find / -xdev -name *.rpm 搜索以 ‘.rpm’ 结尾的文件，忽略光驱、捷盘等可移动设备locate *.ps 寻找以 ‘.ps’ 结尾的文件 - 先运行 ‘updatedb’ 命令whereis halt 显示一个二进制文件、源码或man的位置which halt 显示一个二进制文件或可执行文件的完整路径 挂载一个文件系统mount /dev/hda2 /mnt/hda2 挂载一个叫做hda2的盘 - 确定目录 ‘/ mnt/hda2’ 已经存在umount /dev/hda2 卸载一个叫做hda2的盘 - 先从挂载点 ‘/ mnt/hda2’ 退出fuser -km /mnt/hda2 当设备繁忙时强制卸载umount -n /mnt/hda2 运行卸载操作而不写入 /etc/mtab 文件- 当文件为只读或当磁盘写满时非常有用mount /dev/fd0 /mnt/floppy 挂载一个软盘mount /dev/cdrom /mnt/cdrom 挂载一个cdrom或dvdrommount /dev/hdc /mnt/cdrecorder 挂载一个cdrw或dvdrommount /dev/hdb /mnt/cdrecorder 挂载一个cdrw或dvdrommount -o loop file.iso /mnt/cdrom 挂载一个文件或ISO镜像文件mount -t vfat /dev/hda5 /mnt/hda5 挂载一个Windows FAT32文件系统mount /dev/sda1 /mnt/usbdisk 挂载一个usb 捷盘或闪存设备mount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share 挂载一个windows网络共享 磁盘空间df -h 显示已经挂载的分区列表ls -lSr |more 以尺寸大小排列文件和目录du -sh dir1 估算目录 ‘dir1’ 已经使用的磁盘空间’du -sk * | sort -rn 以容量大小为依据依次显示文件和目录的大小rpm -q -a –qf ‘%10{SIZE}t%{NAME}n’ | sort -k1,1n 以大小为依据依次显示已安装的rpm包所使用的空间 (fedora, redhat类系统)dpkg-query -W -f=’${Installed-Size;10}t${Package}n’ | sort -k1,1n 以大小为依据显示已安装的deb包所使用的空间 (ubuntu, debian类系统) 用户和群组groupadd group_name 创建一个新用户组groupdel group_name 删除一个用户组groupmod -n new_group_name old_group_name 重命名一个用户组useradd -c “Name Surname “ -g admin -d /home/user1 -s /bin/bash user1 创建一个属于 “admin” 用户组的用户useradd user1 创建一个新用户userdel -r user1 删除一个用户 ( ‘-r’ 排除主目录)usermod -c “User FTP” -g system -d /ftp/user1 -s /bin/nologin user1 修改用户属性passwd 修改口令passwd user1 修改一个用户的口令 (只允许root执行)chage -E 2005-12-31 user1 设置用户口令的失效期限pwck 检查 ‘/etc/passwd’ 的文件格式和语法修正以及存在的用户grpck 检查 ‘/etc/passwd’ 的文件格式和语法修正以及存在的群组newgrp group_name 登陆进一个新的群组以改变新创建文件的预设群组 文件的权限 - 使用 “+” 设置权限，使用 “-“ 用于取消ls -lh 显示权限ls /tmp | pr -T5 -W$COLUMNS 将终端划分成5栏显示chmod ugo+rwx directory1 设置目录的所有人(u)、群组(g)以及其他人(o)以读（r ）、写(w)和执行(x)的权限chmod go-rwx directory1 删除群组(g)与其他人(o)对目录的读写执行权限chown user1 file1 改变一个文件的所有人属性chown -R user1 directory1 改变一个目录的所有人属性并同时改变改目录下所有文件的属性chgrp group1 file1 改变文件的群组chown user1:group1 file1 改变一个文件的所有人和群组属性find / -perm -u+s 罗列一个系统中所有使用了SUID控制的文件chmod u+s /bin/file1 设置一个二进制文件的 SUID 位 - 运行该文件的用户也被赋予和所有者同样的权限chmod u-s /bin/file1 禁用一个二进制文件的 SUID位chmod g+s /home/public 设置一个目录的SGID 位 - 类似SUID ，不过这是针对目录的chmod g-s /home/public 禁用一个目录的 SGID 位chmod o+t /home/public 设置一个文件的 STIKY 位 - 只允许合法所有人删除文件chmod o-t /home/public 禁用一个目录的 STIKY 位 文件的特殊属性 - 使用 “+” 设置权限，使用 “-“ 用于取消chattr +a file1 只允许以追加方式读写文件chattr +c file1 允许这个文件能被内核自动压缩/解压chattr +d file1 在进行文件系统备份时，dump程序将忽略这个文件chattr +i file1 设置成不可变的文件，不能被删除、修改、重命名或者链接chattr +s file1 允许一个文件被安全地删除chattr +S file1 一旦应用程序对这个文件执行了写操作，使系统立刻把修改的结果写到磁盘chattr +u file1 若文件被删除，系统会允许你在以后恢复这个被删除的文件lsattr 显示特殊的属性 打包和压缩文件bunzip2 file1.bz2 解压一个叫做 ‘file1.bz2’的文件bzip2 file1 压缩一个叫做 ‘file1’ 的文件gunzip file1.gz 解压一个叫做 ‘file1.gz’的文件gzip file1 压缩一个叫做 ‘file1’的文件gzip -9 file1 最大程度压缩rar a file1.rar test_file 创建一个叫做 ‘file1.rar’ 的包rar a file1.rar file1 file2 dir1 同时压缩 ‘file1’, ‘file2’ 以及目录 ‘dir1’rar x file1.rar 解压rar包unrar x file1.rar 解压rar包tar -cvf archive.tar file1 创建一个非压缩的 tarballtar -cvf archive.tar file1 file2 dir1 创建一个包含了 ‘file1’, ‘file2’ 以及 ‘dir1’的档案文件tar -tf archive.tar 显示一个包中的内容tar -xvf archive.tar 释放一个包tar -xvf archive.tar -C /tmp 将压缩包释放到 /tmp目录下tar -cvfj archive.tar.bz2 dir1 创建一个bzip2格式的压缩包tar -jxvf archive.tar.bz2 解压一个bzip2格式的压缩包tar -cvfz archive.tar.gz dir1 创建一个gzip格式的压缩包tar -zxvf archive.tar.gz 解压一个gzip格式的压缩包zip file1.zip file1 创建一个zip格式的压缩包zip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包unzip file1.zip 解压一个zip格式压缩包 RPM 包 - （Fedora, Redhat及类似系统）rpm -ivh package.rpm 安装一个rpm包rpm -ivh –nodeeps package.rpm 安装一个rpm包而忽略依赖关系警告rpm -U package.rpm 更新一个rpm包但不改变其配置文件rpm -F package.rpm 更新一个确定已经安装的rpm包rpm -e package_name.rpm 删除一个rpm包rpm -qa 显示系统中所有已经安装的rpm包rpm -qa | grep httpd 显示所有名称中包含 “httpd” 字样的rpm包rpm -qi package_name 获取一个已安装包的特殊信息rpm -qg “System Environment/Daemons” 显示一个组件的rpm包rpm -ql package_name 显示一个已经安装的rpm包提供的文件列表rpm -qc package_name 显示一个已经安装的rpm包提供的配置文件列表rpm -q package_name –whatrequires 显示与一个rpm包存在依赖关系的列表rpm -q package_name –whatprovides 显示一个rpm包所占的体积rpm -q package_name –scripts 显示在安装/删除期间所执行的脚本lrpm -q package_name –changelog 显示一个rpm包的修改历史rpm -qf /etc/httpd/conf/httpd.conf 确认所给的文件由哪个rpm包所提供rpm -qp package.rpm -l 显示由一个尚未安装的rpm包提供的文件列表rpm –import /media/cdrom/RPM-GPG-KEY 导入公钥数字证书rpm –checksig package.rpm 确认一个rpm包的完整性rpm -qa gpg-pubkey 确认已安装的所有rpm包的完整性rpm -V package_name 检查文件尺寸、 许可、类型、所有者、群组、MD5检查以及最后修改时间rpm -Va 检查系统中所有已安装的rpm包- 小心使用rpm -Vp package.rpm 确认一个rpm包还未安装rpm2cpio package.rpm | cpio –extract –make-directories bin 从一个rpm包运行可执行文件rpm -ivh /usr/src/redhat/RPMS/arch/package.rpm 从一个rpm源码安装一个构建好的包rpmbuild –rebuild package_name.src.rpm 从一个rpm源码构建一个 rpm 包 YUM 软件包升级器 - （Fedora, RedHat及类似系统）yum install package_name 下载并安装一个rpm包yum localinstall package_name.rpm 将安装一个rpm包，使用你自己的软件仓库为你解决所有依赖关系yum update package_name.rpm 更新当前系统中所有安装的rpm包yum update package_name 更新一个rpm包yum remove package_name 删除一个rpm包yum list 列出当前系统中安装的所有包yum search package_name 在rpm仓库中搜寻软件包yum clean packages 清理rpm缓存删除下载的包yum clean headers 删除所有头文件yum clean all 删除所有缓存的包和头文件 DEB 包 (Debian, Ubuntu 以及类似系统)dpkg -i package.deb 安装/更新一个 deb 包dpkg -r package_name 从系统删除一个 deb 包dpkg -l 显示系统中所有已经安装的 deb 包dpkg -l | grep httpd 显示所有名称中包含 “httpd” 字样的deb包dpkg -s package_name 获得已经安装在系统中一个特殊包的信息dpkg -L package_name 显示系统中已经安装的一个deb包所提供的文件列表dpkg –contents package.deb 显示尚未安装的一个包所提供的文件列表dpkg -S /bin/ping 确认所给的文件由哪个deb包提供 APT 软件工具 (Debian, Ubuntu 以及类似系统)apt-get install package_name 安装/更新一个 deb 包apt-cdrom install package_name 从光盘安装/更新一个 deb 包apt-get update 升级列表中的软件包apt-get upgrade 升级所有已安装的软件apt-get remove package_name 从系统删除一个deb包apt-get check 确认依赖的软件仓库正确apt-get clean 从下载的软件包中清理缓存apt-cache search searched-package 返回包含所要搜索字符串的软件包名称 查看文件内容cat file1 从第一个字节开始正向查看文件的内容tac file1 从最后一行开始反向查看一个文件的内容more file1 查看一个长文件的内容less file1 类似于 ‘more’ 命令，但是它允许在文件中和正向操作一样的反向操作head -2 file1 查看一个文件的前两行tail -2 file1 查看一个文件的最后两行tail -f /var/log/messages 实时查看被添加到一个文件中的内容 文本处理cat file1 file2 … | command &lt;&gt; file1_in.txt_or_file1_out.txt general syntax for text manipulation using PIPE, STDIN and STDOUTcat file1 | command( sed, grep, awk, grep, etc…) &gt; result.txt 合并一个文件的详细说明文本，并将简介写入一个新文件中cat file1 | command( sed, grep, awk, grep, etc…) &gt;&gt; result.txt 合并一个文件的详细说明文本，并将简介写入一个已有的文件中grep Aug /var/log/messages 在文件 ‘/var/log/messages’中查找关键词”Aug”grep ^Aug /var/log/messages 在文件 ‘/var/log/messages’中查找以”Aug”开始的词汇grep [0-9] /var/log/messages 选择 ‘/var/log/messages’ 文件中所有包含数字的行grep Aug -R /var/log/* 在目录 ‘/var/log’ 及随后的目录中搜索字符串”Aug”sed ‘s/stringa1/stringa2/g’ example.txt 将example.txt文件中的 “string1” 替换成 “string2”sed ‘/^$/d’ example.txt 从example.txt文件中删除所有空白行sed ‘/ *#/d; /^$/d’ example.txt 从example.txt文件中删除所有注释和空白行echo ‘esempio’ | tr ‘[:lower:]’ ‘[:upper:]’ 合并上下单元格内容sed -e ‘1d’ result.txt 从文件example.txt 中排除第一行sed -n ‘/stringa1/p’ 查看只包含词汇 “string1”的行sed -e ‘s/ $//‘ example.txt 删除每一行最后的空白字符sed -e ‘s/stringa1//g’ example.txt 从文档中只删除词汇 “string1” 并保留剩余全部sed -n ‘1,5p;5q’ example.txt 查看从第一行到第5行内容sed -n ‘5p;5q’ example.txt 查看第5行sed -e ‘s/00/0/g’ example.txt 用单个零替换多个零cat -n file1 标示文件的行数cat example.txt | awk ‘NR%2==1’ 删除example.txt文件中的所有偶数行echo a b c | awk ‘{print $1}’ 查看一行第一栏echo a b c | awk ‘{print $1,$3}’ 查看一行的第一和第三栏paste file1 file2 合并两个文件或两栏的内容paste -d ‘+’ file1 file2 合并两个文件或两栏的内容，中间用”+”区分sort file1 file2 排序两个文件的内容sort file1 file2 | uniq 取出两个文件的并集(重复的行只保留一份)sort file1 file2 | uniq -u 删除交集，留下其他的行sort file1 file2 | uniq -d 取出两个文件的交集(只留下同时存在于两个文件中的文件)comm -1 file1 file2 比较两个文件的内容只删除 ‘file1’ 所包含的内容comm -2 file1 file2 比较两个文件的内容只删除 ‘file2’ 所包含的内容comm -3 file1 file2 比较两个文件的内容只删除两个文件共有的部分 字符设置和文件格式转换dos2unix filedos.txt fileunix.txt 将一个文本文件的格式从MSDOS转换成UNIXunix2dos fileunix.txt filedos.txt 将一个文本文件的格式从UNIX转换成MSDOSrecode ..HTML &lt; page.txt &gt; page.html 将一个文本文件转换成htmlrecode -l | more 显示所有允许的转换格式 文件系统分析badblocks -v /dev/hda1 检查磁盘hda1上的坏磁块fsck /dev/hda1 修复/检查hda1磁盘上linux文件系统的完整性fsck.ext2 /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性e2fsck /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性e2fsck -j /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性fsck.ext3 /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性fsck.vfat /dev/hda1 修复/检查hda1磁盘上fat文件系统的完整性fsck.msdos /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性dosfsck /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性 初始化一个文件系统mkfs /dev/hda1 在hda1分区创建一个文件系统mke2fs /dev/hda1 在hda1分区创建一个linux ext2的文件系统mke2fs -j /dev/hda1 在hda1分区创建一个linux ext3(日志型)的文件系统mkfs -t vfat 32 -F /dev/hda1 创建一个 FAT32 文件系统fdformat -n /dev/fd0 格式化一个软盘mkswap /dev/hda3 创建一个swap文件系统 SWAP文件系统mkswap /dev/hda3 创建一个swap文件系统swapon /dev/hda3 启用一个新的swap文件系统swapon /dev/hda2 /dev/hdb3 启用两个swap分区 备份dump -0aj -f /tmp/home0.bak /home 制作一个 ‘/home’ 目录的完整备份dump -1aj -f /tmp/home0.bak /home 制作一个 ‘/home’ 目录的交互式备份restore -if /tmp/home0.bak 还原一个交互式备份rsync -rogpav –delete /home /tmp 同步两边的目录rsync -rogpav -e ssh –delete /home ip_address:/tmp 通过SSH通道rsyncrsync -az -e ssh –delete ip_addr:/home/public /home/local 通过ssh和压缩将一个远程目录同步到本地目录rsync -az -e ssh –delete /home/local ip_addr:/home/public 通过ssh和压缩将本地目录同步到远程目录dd bs=1M if=/dev/hda | gzip | ssh user@ip_addr ‘dd of=hda.gz’ 通过ssh在远程主机上执行一次备份本地磁盘的操作dd if=/dev/sda of=/tmp/file1 备份磁盘内容到一个文件tar -Puf backup.tar /home/user 执行一次对 ‘/home/user’ 目录的交互式备份操作( cd /tmp/local/ &amp;&amp; tar c . ) | ssh -C user@ip_addr ‘cd /home/share/ &amp;&amp; tar x -p’ 通过ssh在远程目录中复制一个目录内容( tar c /home ) | ssh -C user@ip_addr ‘cd /home/backup-home &amp;&amp; tar x -p’ 通过ssh在远程目录中复制一个本地目录tar cf - . | (cd /tmp/backup ; tar xf - ) 本地将一个目录复制到另一个地方，保留原有权限及链接find /home/user1 -name ‘.txt’ | xargs cp -av –target-directory=/home/backup/ –parents 从一个目录查找并复制所有以 ‘.txt’ 结尾的文件到另一个目录find /var/log -name ‘.log’ | tar cv –files-from=- | bzip2 &gt; log.tar.bz2 查找所有以 ‘.log’ 结尾的文件并做成一个bzip包dd if=/dev/hda of=/dev/fd0 bs=512 count=1 做一个将 MBR (Master Boot Record)内容复制到软盘的动作dd if=/dev/fd0 of=/dev/hda bs=512 count=1 从已经保存到软盘的备份中恢复MBR内容 光盘cdrecord -v gracetime=2 dev=/dev/cdrom -eject blank=fast -force 清空一个可复写的光盘内容mkisofs /dev/cdrom &gt; cd.iso 在磁盘上创建一个光盘的iso镜像文件mkisofs /dev/cdrom | gzip &gt; cd_iso.gz 在磁盘上创建一个压缩了的光盘iso镜像文件mkisofs -J -allow-leading-dots -R -V “Label CD” -iso-level 4 -o ./cd.iso data_cd 创建一个目录的iso镜像文件cdrecord -v dev=/dev/cdrom cd.iso 刻录一个ISO镜像文件gzip -dc cd_iso.gz | cdrecord dev=/dev/cdrom - 刻录一个压缩了的ISO镜像文件mount -o loop cd.iso /mnt/iso 挂载一个ISO镜像文件cd-paranoia -B 从一个CD光盘转录音轨到 wav 文件中cd-paranoia – “-3” 从一个CD光盘转录音轨到 wav 文件中（参数-3）cdrecord –scanbus 扫描总线以识别scsi通道dd if=/dev/hdc | md5sum 校验一个设备的md5sum编码，例如一张 CD 网络 - （以太网和WIFI无线）ifconfig eth0 显示一个以太网卡的配置ifup eth0 启用一个 ‘eth0’ 网络设备ifdown eth0 禁用一个 ‘eth0’ 网络设备ifconfig eth0 192.168.1.1 netmask 255.255.255.0 控制IP地址ifconfig eth0 promisc 设置 ‘eth0’ 成混杂模式以嗅探数据包 (sniffing)dhclient eth0 以dhcp模式启用 ‘eth0’route -n show routing tableroute add -net 0/0 gw IP_Gateway configura default gatewayroute add -net 192.168.0.0 netmask 255.255.0.0 gw 192.168.1.1 configure static route to reach network ‘192.168.0.0/16’route del 0/0 gw IP_gateway remove static routeecho “1” &gt; /proc/sys/net/ipv4/ip_forward activate ip routinghostname show hostname of systemhost www.example.com lookup hostname to resolve name to ip address and viceversanslookup www.example.com lookup hostname to resolve name to ip address and viceversaip link show show link status of all interfacesmii-tool eth0 show link status of ‘eth0’ethtool eth0 show statistics of network card ‘eth0’netstat -tup show all active network connections and their PIDnetstat -tupl show all network services listening on the system and their PIDtcpdump tcp port 80 show all HTTP trafficiwlist scan show wireless networksiwconfig eth1 show configuration of a wireless network cardhostname show hostnamehost www.example.com lookup hostname to resolve name to ip address and viceversanslookup www.example.com lookup hostname to resolve name to ip address and viceversawhois www.example.com lookup on Whois database JPS工具jps(Java Virtual Machine Process Status Tool)是JDK 1.5提供的一个显示当前所有java进程pid的命令，简单实用，非常适合在linux/unix平台上简单察看当前java进程的一些简单情况。 我想很多人都是用过unix系统里的ps命令，这个命令主要是用来显示当前系统的进程情况，有哪些进程，及其 id。 jps 也是一样，它的作用是显示当前系统的java进程情况，及其id号。我们可以通过它来查看我们到底启动了几个java进程（因为每一个java程序都会独占一个java虚拟机实例），和他们的进程号（为下面几个程序做准备），并可通过opt来查看这些进程的详细启动参数。 使用方法：在当前命令行下打 jps(需要JAVA_HOME，没有的话，到改程序的目录下打) 。 jps存放在JAVA_HOME/bin/jps，使用时为了方便请将JAVA_HOME/bin/加入到Path. $&gt; jps23991 Jps23789 BossMain23651 Resin 比较常用的参数： -q 只显示pid，不显示class名称,jar文件名和传递给main 方法的参数$&gt; jps -q286802378923651 -m 输出传递给main 方法的参数，在嵌入式jvm上可能是null $&gt; jps -m28715 Jps -m23789 BossMain23651 Resin -socketwait 32768 -stdout /data/aoxj/resin/log/stdout.log -stderr /data/aoxj/resin/log/stderr.log -l 输出应用程序main class的完整package名 或者 应用程序的jar文件完整路径名 $&gt; jps -l28729 sun.tools.jps.Jps23789 com.asiainfo.aimc.bossbi.BossMain23651 com.caucho.server.resin.Resin -v 输出传递给JVM的参数 $&gt; jps -v23789 BossMain28802 Jps -Denv.class.path=/data/aoxj/bossbi/twsecurity/java/trustwork140.jar:/data/aoxj/bossbi/twsecurity/java/:/data/aoxj/bossbi/twsecurity/java/twcmcc.jar:/data/aoxj/jdk15/lib/rt.jar:/data/aoxj/jd k15/lib/tools.jar -Dapplication.home=/data/aoxj/jdk15 -Xms8m23651 Resin -Xss1m -Dresin.home=/data/aoxj/resin -Dserver.root=/data/aoxj/resin -Djava.util.logging.manager=com.caucho.log.LogManagerImpl - Djavax.management.builder.initial=com.caucho.jmx.MBeanServerBuilderImpl sudo jps看到的进程数量最全 jps 192.168.0.77 列出远程服务器192.168.0.77机器所有的jvm实例，采用rmi协议，默认连接端口为1099 （前提是远程服务器提供jstatd服务） 注：jps命令有个地方很不好，似乎只能显示当前用户的java进程，要显示其他用户的还是只能用unix/linux的ps命令。 转自：https://www.cnblogs.com/yjd_hycf_space/p/7730690.html 详细情况请参考sun官方文档。http://java.sun.com/j2se/1.7.0/docs/tooldocs/share/jps.html","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"Linux","slug":"教程/Linux","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Linux/"}],"tags":[{"name":"命令","slug":"命令","permalink":"https://hutaozhang.github.io/tags/%E5%91%BD%E4%BB%A4/"},{"name":"Linux","slug":"Linux","permalink":"https://hutaozhang.github.io/tags/Linux/"}]},{"title":"Jedis-Redis的Java的应用","slug":"Jedis-Redis与Java的应用","date":"2021-01-20T03:19:18.288Z","updated":"2021-02-24T17:25:44.816Z","comments":true,"path":"posts/14870.html","link":"","permalink":"https://hutaozhang.github.io/posts/14870.html","excerpt":"","text":"转载：Redis入门到精通-Redis与Java的应用 1. Jedis的使用Jedis就是redis支持java的第三方类库，我们可以使用Jedis类库操作redis数据库。 ​ 注意:Jedis2.7以上的版本才支持集群操作。 1.1 Maven依赖12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt;&lt;/dependency&gt; 1.2 连接redis服务12Jedis jedis = new Jedis(&quot;10.0.31.144&quot;,6379); //默认端口6379 可以省略jedis.auth(&quot;redis&quot;); //无密码此步可省略 1.3 Redis Java String(字符串)12345Jedis jedis = new Jedis(&quot;10.0.31.144&quot;,6379);jedis.auth(&quot;redis&quot;);​jedis.set(&quot;a&quot;, &quot;test1&quot;); // 存数据System.out.println(jedis.get(&quot;a&quot;)); // 取数据 1.4 Redis Java List(列表)123456789101112Jedis jedis = new Jedis(&quot;10.0.31.144&quot;,6379);jedis.auth(&quot;redis&quot;);​//存储数据到列表中jedis.lpush(&quot;list1&quot;, &quot;Java&quot;);jedis.lpush(&quot;list1&quot;, &quot;Html5&quot;);jedis.lpush(&quot;list1&quot;, &quot;Python&quot;);// 获取存储的数据并输出List&lt;String&gt; list = jedis.lrange(&quot;list1&quot;, 0 ,-1);for(int i=0; i&lt;list.size(); i++) &#123; System.out.println(&quot;列表项为: &quot;+list.get(i));&#125; 1.5 Redis Java Keys12345678910Jedis jedis = new Jedis(&quot;10.0.31.144&quot;,6379);jedis.auth(&quot;redis&quot;);​// 获取数据并输出Set&lt;String&gt; keys = jedis.keys(&quot;*&quot;);Iterator&lt;String&gt; it=keys.iterator() ;while(it.hasNext())&#123; String key = it.next(); System.out.println(key);&#125; 2. 将User表放入到 Redis缓存 ​ t_user表数据量很大，查询很频繁，鲜有更新操作，可以把t_user表放到redis缓存中，实现t_user表的快速查询。 ​ 测试过程中我们用到了object转jsonString 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.12&lt;/version&gt;&lt;/dependency&gt; 2.1 准备User.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class User &#123; private String id; private String name; private int age; private String sex;​ public User() &#123; super(); &#125;​ public User(String id, String name, int age, String sex) &#123; super(); this.id = id; this.name = name; this.age = age; this.sex = sex; &#125;​ public String getId() &#123; return id; &#125;​ public void setId(String id) &#123; this.id = id; &#125;​ public String getName() &#123; return name; &#125;​ public void setName(String name) &#123; this.name = name; &#125;​ public int getAge() &#123; return age; &#125;​ public void setAge(int age) &#123; this.age = age; &#125;​ public String getSex() &#123; return sex; &#125;​ public void setSex(String sex) &#123; this.sex = sex; &#125;​ @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;id=&quot; + id + &quot;, name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, age=&quot; + age + &quot;, sex=&#x27;&quot; + sex + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 2.2 将User的数据放入到Redis1234567891011121314151617Jedis jedis = new Jedis(&quot;10.0.31.144&quot;,6379);jedis.auth(&quot;redis&quot;);​User u1 = new User(UUID.randomUUID().toString(),&quot;jack1&quot;,21,&quot;m&quot;);User u2 = new User(UUID.randomUUID().toString(),&quot;jack2&quot;,22,&quot;m&quot;);User u3 = new User(UUID.randomUUID().toString(),&quot;jack3&quot;,23,&quot;m&quot;);User u4 = new User(UUID.randomUUID().toString(),&quot;jack4&quot;,24,&quot;m&quot;);User u5 = new User(UUID.randomUUID().toString(),&quot;jack5&quot;,25,&quot;m&quot;);​Map&lt;String,String&gt; userMap = new HashMap&lt;String,String&gt;();userMap.put(&quot;u1&quot;,JSON.toJSONString(u1));userMap.put(&quot;u2&quot;,JSON.toJSONString(u2));userMap.put(&quot;u3&quot;,JSON.toJSONString(u3));userMap.put(&quot;u4&quot;,JSON.toJSONString(u4));userMap.put(&quot;u5&quot;,JSON.toJSONString(u5));​jedis.hmset(&quot;t_user&quot;,userMap); 到Redis数据库服务器上观察： 123456789101112131415127.0.0.1:6379&gt; keys *1) &quot;t_user&quot;127.0.0.1:6379&gt; hkeys t_user1) &quot;u1&quot;2) &quot;u3&quot;3) &quot;u4&quot;4) &quot;u5&quot;5) &quot;u2&quot;127.0.0.1:6379&gt; hvals t_user1) &quot;&#123;\\&quot;age\\&quot;:21,\\&quot;id\\&quot;:\\&quot;740a1778-de0e-4426-b231-1f97d290b13c\\&quot;,\\&quot;name\\&quot;:\\&quot;jack1\\&quot;,\\&quot;sex\\&quot;:\\&quot;m\\&quot;&#125;&quot;2) &quot;&#123;\\&quot;age\\&quot;:23,\\&quot;id\\&quot;:\\&quot;5133d99f-b8a0-4062-8624-89a5dc5c8e89\\&quot;,\\&quot;name\\&quot;:\\&quot;jack3\\&quot;,\\&quot;sex\\&quot;:\\&quot;m\\&quot;&#125;&quot;3) &quot;&#123;\\&quot;age\\&quot;:24,\\&quot;id\\&quot;:\\&quot;f6d1a709-5f2c-4564-bec6-b8f63eef6a86\\&quot;,\\&quot;name\\&quot;:\\&quot;jack4\\&quot;,\\&quot;sex\\&quot;:\\&quot;m\\&quot;&#125;&quot;4) &quot;&#123;\\&quot;age\\&quot;:25,\\&quot;id\\&quot;:\\&quot;4c8b4122-c9f9-41b2-ba29-c0de2a257370\\&quot;,\\&quot;name\\&quot;:\\&quot;jack5\\&quot;,\\&quot;sex\\&quot;:\\&quot;m\\&quot;&#125;&quot;5) &quot;&#123;\\&quot;age\\&quot;:22,\\&quot;id\\&quot;:\\&quot;e48c6616-75c2-4d04-9e90-31b69a4632a4\\&quot;,\\&quot;name\\&quot;:\\&quot;jack2\\&quot;,\\&quot;sex\\&quot;:\\&quot;m\\&quot;&#125;&quot;127.0.0.1:6379&gt; 2.3 使用Redis中的User缓存数据t_user表数据量大，查询缓慢，如何实现t_user表数据的快速查询； 123​select * from t_user where age =25;select * from t_user where sex = &#x27;m&#x27;；​select * from t_user where sex = &#x27;w&#x27;； ​ 我们可以使用redis中的set类型预先设定查询结果集。 1234567891011121314151617181920212223242526272829303132333435​Jedis jedis = new Jedis(&quot;10.0.31.144&quot;,6379);jedis.auth(&quot;redis&quot;);​//假设现在有mybatis的三个查询操作//userMapper.getUserListByAge(25)//userMapper.getUserListBySex(&quot;m&quot;)//userMapper.getUserListBySex(&quot;f&quot;)​//预设查询结果集final String user_list_by_age_25 = &quot;user_list_by_age_25&quot;;final String user_list_by_sex_m = &quot;user_list_by_sex_m&quot;;final String user_list_by_sex_f = &quot;user_list_by_sex_f&quot;;​//在初始化redis缓存的时候,模拟预设查询结果集// (在真正的开发中,使用mybatis二级换从数据库查询后再缓存到redis)//定义userMap存放t_user表的所有数据Map&lt;String,String&gt; userMap = new HashMap&lt;String,String&gt;();​User u1 = new User(UUID.randomUUID().toString(),&quot;jack&quot;,21,&quot;m&quot;);userMap.put(&quot;u1&quot;,JSON.toJSONString(u1));//u1 满足性别为m的条件,即u1为userMapper.getUserListBySex(&quot;m&quot;)的查询结果集jedis.sadd(user_list_by_sex_m,&quot;u1&quot;);​User u2 = new User(UUID.randomUUID().toString(),&quot;rose&quot;,25,&quot;f&quot;);userMap.put(&quot;u2&quot;,JSON.toJSONString(u2));//u2 满足sex=&#x27;f&#x27; age=25jedis.sadd(user_list_by_sex_f,&quot;u2&quot;);jedis.sadd(user_list_by_age_25,&quot;u2&quot;);​User u3 = new User(UUID.randomUUID().toString(),&quot;jack3&quot;,23,&quot;m&quot;);userMap.put(&quot;u3&quot;,JSON.toJSONString(u3));//u3 满足sex=&#x27;m&#x27;jedis.sadd(user_list_by_sex_m,&quot;u3&quot;);​jedis.hmset(&quot;t_user&quot;,userMap); Redis服务器结果： 123456789101112131415161718192021127.0.0.1:6379&gt; keys *1) &quot;user_list_by_age_25&quot;2) &quot;user_list_by_sex_m&quot;3) &quot;t_user&quot;4) &quot;user_list_by_sex_f&quot;127.0.0.1:6379&gt; hkeys t_user1) &quot;u1&quot;2) &quot;u2&quot;3) &quot;u3&quot;127.0.0.1:6379&gt; hvals t_user1) &quot;&#123;\\&quot;age\\&quot;:21,\\&quot;id\\&quot;:\\&quot;65224362-26b7-4858-9dfd-6c8df8d0dcce\\&quot;,\\&quot;name\\&quot;:\\&quot;jack\\&quot;,\\&quot;sex\\&quot;:\\&quot;m\\&quot;&#125;&quot;2) &quot;&#123;\\&quot;age\\&quot;:25,\\&quot;id\\&quot;:\\&quot;cd23782e-90a5-4c80-8c31-d0c874e623f6\\&quot;,\\&quot;name\\&quot;:\\&quot;rose\\&quot;,\\&quot;sex\\&quot;:\\&quot;f\\&quot;&#125;&quot;3) &quot;&#123;\\&quot;age\\&quot;:23,\\&quot;id\\&quot;:\\&quot;e5bb2423-c821-4267-b77c-0abef4777113\\&quot;,\\&quot;name\\&quot;:\\&quot;jack3\\&quot;,\\&quot;sex\\&quot;:\\&quot;m\\&quot;&#125;&quot;127.0.0.1:6379&gt; smembers user_list_by_age_251) &quot;u2&quot;127.0.0.1:6379&gt; smembers user_list_by_sex_m1) &quot;u1&quot;2) &quot;u3&quot;127.0.0.1:6379&gt; smembers user_list_by_sex_f1) &quot;u2&quot;127.0.0.1:6379&gt; ​ 这样在程序中userMapper.getUserListByAge(25)就可以通过从redis服务器上获得user_list_by_age_25数据进行使用。 12345678Jedis jedis = new Jedis(&quot;10.0.31.144&quot;,6379);jedis.auth(&quot;redis&quot;);Set&lt;String&gt; userlist = jedis.smembers(&quot;user_list_by_sex_m&quot;);for(String u : userlist)&#123; //拿到对对应ser的json字符串 System.out.println(jedis.hget(&quot;t_user&quot;,u)); //...这里可以再使用json转object方法&#125;","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"Jedis","slug":"教程/Jedis","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Jedis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://hutaozhang.github.io/tags/Redis/"},{"name":"Jedis","slug":"Jedis","permalink":"https://hutaozhang.github.io/tags/Jedis/"},{"name":"Java","slug":"Java","permalink":"https://hutaozhang.github.io/tags/Java/"}]},{"title":"Redis搭建及使用","slug":"Redis-build","date":"2021-01-20T03:19:18.284Z","updated":"2021-02-24T17:25:44.828Z","comments":true,"path":"posts/1928.html","link":"","permalink":"https://hutaozhang.github.io/posts/1928.html","excerpt":"","text":"Docker 安装 Redis 系统环境：16.04.1-Ubuntu uname -a 获取 Redis 镜像 docker images #检查是否存在redis镜像 若已存在镜像 docker ps -a -q #查看镜像是否在运行 docker exec -it redis_test redis-server -v #redis_test 是运行redis名称 若不存在镜像 docker search redis #查看redis版本 docker pull redis:latest #获取最新redis版本 启动 Redis docker run -d -p 6379:6379 --name redis_test --restart=always redis #启动一个简单的redis服务 docker run -d -p 6379:6379 --name redis_test -v /usr/local/redis/redis.conf:/etc/redis/redis.conf --restart=always redis redis-server /etc/redis/redis.conf #配置文件见附件一 -d 后台运行 –restart=always #开机自启 -v #挂载路径：/usr/local/redis/redis.conf redis-server #以配置文件(/etc/redis/redis.conf)方式启动，配合-v使用;配置文件注意事项： bind 127.0.0.1 #注释掉这部分(同时protected-mode no)，这是限制redis只能本地访问 dir ./ #存放路径，（同时appendonly yes） #持久化搭配使用 protected-mode no #默认yes，开启保护模式，限制为本地访问 daemonize no#默认no，改为yes意为以守护进程方式启动，可后台运行，除非kill进程（可选），改为yes会使配置文件方式启动redis失败 测试docker exec -it redis_test redis-cliauth 123456 外部连接 软件：Another Redis Desktop Manager 下载：Gitee Github Redis Desktop Manager 免费版不支持SSH连接 Redis常用命令及Java使用 命令行 开启redis，进入命令行界面 设置缓存：set key value 获取缓存：get key 设置过期时间：setex key 失效时间(s) value 删除缓存：del key 工具使用 Redis Java 添加 pom.xml12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt; &lt;/dependency&gt; application配置信息 123456789101112redis: database: 0 host: 127.0.0.1 port: 6379 password: # 如果未单独配置默认为空即可 timeout: 1000 jedis: pool: max-active: 8 max-wait: -1 max-idle: 8 min-idle: 0 jedis配置类Jedis - Redis与Java的应用整合springboot1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 @EnableCaching@Configurationpublic class RedisConfig &#123; @Value(&quot;$&#123;spring.redis.host&#125;&quot;) private String host; @Value(&quot;$&#123;spring.redis.database&#125;&quot;) private Integer database; @Value(&quot;$&#123;spring.redis.port&#125;&quot;) private Integer port; @Value(&quot;$&#123;spring.redis.password&#125;&quot;) private String pwd; @Primary @Bean(name = &quot;jedisPoolConfig&quot;) @ConfigurationProperties(prefix = &quot;spring.redis.pool&quot;) public JedisPoolConfig jedisPoolConfig() &#123; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxWaitMillis(10000); return jedisPoolConfig; &#125; @Bean public RedisConnectionFactory redisConnectionFactory(JedisPoolConfig jedisPoolConfig) &#123; RedisStandaloneConfiguration redisStandaloneConfiguration = new RedisStandaloneConfiguration(); redisStandaloneConfiguration.setHostName(host); redisStandaloneConfiguration.setDatabase(database); redisStandaloneConfiguration.setPassword(pwd); redisStandaloneConfiguration.setPort(port); JedisClientConfiguration.JedisPoolingClientConfigurationBuilder jpcb = (JedisClientConfiguration.JedisPoolingClientConfigurationBuilder) JedisClientConfiguration.builder(); jpcb.poolConfig(jedisPoolConfig); JedisClientConfiguration jedisClientConfiguration = jpcb.build(); return new JedisConnectionFactory(redisStandaloneConfiguration, jedisClientConfiguration); &#125; /** * 配置redisTemplate针对不同key和value场景下不同序列化的方式 * * @param factory Redis连接工厂 * @return */ @Primary @Bean(name = &quot;redisTemplate&quot;) public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(factory); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); template.setKeySerializer(stringRedisSerializer); template.setHashKeySerializer(stringRedisSerializer); Jackson2JsonRedisSerializer redisSerializer = new Jackson2JsonRedisSerializer(Object.class); template.setValueSerializer(redisSerializer); template.setHashValueSerializer(redisSerializer); template.afterPropertiesSet(); return template; &#125; @Bean IGlobalCache cache(RedisTemplate redisTemplate) &#123; return new AppRedisCacheManager(redisTemplate); &#125; &#125; redisTemplate封装 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376 /** * 系统全局Cache接口，具体缓存方式需要实现该接口 * * @author YuXD * @date 2021-01-05 10:38 * @since v1.0 */public interface IGlobalCache &#123; /** * 指定缓存失效时间 * * @param key 键 * @param time 时间(秒) * @return */ boolean expire(String key, long time); /** * @param key 键 不能为null * @return 时间(秒) 返回0代表为永久有效 */ long getExpire(String key); /** * 判断key是否存在 * * @param key 键 * @return true 存在 false不存在 */ boolean hasKey(String key); /** * 删除缓存 * * @param key 可以传一个值 或多个 */ void del(String... key);// ============================String============================= /** * 普通缓存获取 * * @param key 键 * @return 值 */ Object get(String key); /** * 普通缓存放入 * * @param key 键 * @param value 值 * @return true成功 false失败 */ boolean set(String key, Object value); /** * 普通缓存放入并设置时间 * * @param key 键 * @param value 值 * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期 * @return true成功 false 失败 */ boolean set(String key, Object value, long time); /** * 递增 * * @param key 键 * @param delta 要增加几(大于0) * @return */ long incr(String key, long delta); /** * 递减 * * @param key 键 * @param delta 要减少几(小于0) * @return */ long decr(String key, long delta); /** * HashGet * * @param key 键 不能为null * @param item 项 不能为null * @return 值 */ Object hget(String key, String item); /** * 获取hashKey对应的所有键值 * * @param key 键 * @return 对应的多个键值 */ Map&lt;Object, Object&gt; hmget(String key); /** * HashSet * * @param key 键 * @param map 对应多个键值 * @return true 成功 false 失败 */ boolean hmset(String key, Map&lt;String, Object&gt; map); /** * HashSet 并设置时间 * * @param key 键 * @param map 对应多个键值 * @param time 时间(秒) * @return true成功 false失败 */ boolean hmset(String key, Map&lt;String, Object&gt; map, long time); /** * 向一张hash表中放入数据,如果不存在将创建 * * @param key 键 * @param item 项 * @param value 值 * @return true 成功 false失败 */ boolean hset(String key, String item, Object value); /** * 向一张hash表中放入数据,如果不存在将创建 * * @param key 键 * @param item 项 * @param value 值 * @param time 时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间 * @return true 成功 false失败 */ boolean hset(String key, String item, Object value, long time); /** * 删除hash表中的值 * * @param key 键 不能为null * @param item 项 可以使多个 不能为null */ void hdel(String key, Object... item); /** * 判断hash表中是否有该项的值 * * @param key 键 不能为null * @param item 项 不能为null * @return true 存在 false不存在 */ boolean hHasKey(String key, String item); /** * hash递增 如果不存在,就会创建一个 并把新增后的值返回 * * @param key 键 * @param item 项 * @param by 要增加几(大于0) * @return */ double hincr(String key, String item, double by); /** * hash递减 * * @param key 键 * @param item 项 * @param by 要减少记(小于0) * @return */ double hdecr(String key, String item, double by); /** * 根据key获取Set中的所有值 * * @param key 键 * @return */ Set&lt;Object&gt; sGet(String key); /** * 根据value从一个set中查询,是否存在 * * @param key 键 * @param value 值 * @return true 存在 false不存在 */ boolean sHasKey(String key, Object value); /** * 将数据放入set缓存 * * @param key 键 * @param values 值 可以是多个 * @return 成功个数 */ long sSet(String key, Object... values); /** * 将set数据放入缓存 * * @param key 键 * @param time 时间(秒) * @param values 值 可以是多个 * @return 成功个数 */ long sSetAndTime(String key, long time, Object... values); /** * 获取set缓存的长度 * * @param key 键 * @return */ long sGetSetSize(String key); /** * 移除值为value的 * * @param key 键 * @param values 值 可以是多个 * @return 移除的个数 */ long setRemove(String key, Object... values); /** * 获取list缓存的内容 * * @param key 键 * @param start 开始 * @param end 结束 0 到 -1代表所有值 * @return */ List&lt;Object&gt; lGet(String key, long start, long end); /** * 获取list缓存的长度 * * @param key 键 * @return */ long lGetListSize(String key); /** * 通过索引 获取list中的值 * * @param key 键 * @param index 索引 index&gt;=0时， 0 表头，1 第二个元素，依次类推；index&lt;0时，-1，表尾，-2倒数第二个元素，依次类推 * @return */ Object lGetIndex(String key, long index); /** * 将list放入缓存 * * @param key 键 * @param value 值 * @return */ boolean lSet(String key, Object value); /** * 将list放入缓存 * * @param key 键 * @param value 值 * @return */ boolean lSet(String key, Object value, long time); /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) * @return */ boolean lSetAll(String key, List&lt;Object&gt; value); /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) * @return */ boolean lSetAll(String key, List&lt;Object&gt; value, long time); /** * 将list放入缓存 * * @param key 键 * @param value 值 * @return */ boolean rSet(String key, Object value); /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) * @return */ boolean rSet(String key, Object value, long time); /** * 将list放入缓存 * * @param key 键 * @param value 值 * @return */ boolean rSetAll(String key, List&lt;Object&gt; value); /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) * @return */ boolean rSetAll(String key, List&lt;Object&gt; value, long time); /** * 根据索引修改list中的某条数据 * * @param key 键 * @param index 索引 * @param value 值 * @return */ boolean lUpdateIndex(String key, long index, Object value); /** * 移除N个值为value * * @param key 键 * @param count 移除多少个 * @param value 值 * @return 移除的个数 */ long lRemove(String key, long count, Object value); /** * 从redis集合中移除[start,end]之间的元素 * * @param key * @param stard * @param end * @return */ void rangeRemove(String key, Long stard, Long end); /** * 返回当前redisTemplate * * @return */ RedisTemplate getRedisTemplate();&#125; 附件一 配置文件 redis.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748protected-mode noport 6379tcp-backlog 511timeout 0tcp-keepalive 0loglevel noticelogfile &quot;&quot;databases 16save 900 1save 300 10save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump.rdbdir .&#x2F;slave-serve-stale-data yesslave-read-only yesrepl-diskless-sync norepl-diskless-sync-delay 5repl-disable-tcp-nodelay noslave-priority 100appendonly noappendfilename &quot;appendonly.aof&quot;appendfsync everysecno-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yeslua-time-limit 5000slowlog-log-slower-than 10000slowlog-max-len 128latency-monitor-threshold 0notify-keyspace-events &quot;&quot;hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-size -2list-compress-depth 0set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64hll-sparse-max-bytes 3000activerehashing yesclient-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10aof-rewrite-incremental-fsync yes","categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"Redis","slug":"教程/Redis","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://hutaozhang.github.io/tags/Redis/"},{"name":"Docker","slug":"Docker","permalink":"https://hutaozhang.github.io/tags/Docker/"}]},{"title":"Hello World","slug":"hello-world","date":"2021-01-20T02:09:33.241Z","updated":"2021-02-24T17:25:44.818Z","comments":true,"path":"posts/16107.html","link":"","permalink":"https://hutaozhang.github.io/posts/16107.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"教程","slug":"教程","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/"},{"name":"Spring","slug":"教程/Spring","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Spring/"},{"name":"MySQL","slug":"教程/MySQL","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/MySQL/"},{"name":"Database","slug":"教程/Database","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Database/"},{"name":"面试","slug":"面试","permalink":"https://hutaozhang.github.io/categories/%E9%9D%A2%E8%AF%95/"},{"name":"Database","slug":"面试/Database","permalink":"https://hutaozhang.github.io/categories/%E9%9D%A2%E8%AF%95/Database/"},{"name":"MySQL","slug":"面试/Database/MySQL","permalink":"https://hutaozhang.github.io/categories/%E9%9D%A2%E8%AF%95/Database/MySQL/"},{"name":"MySQL","slug":"面试/MySQL","permalink":"https://hutaozhang.github.io/categories/%E9%9D%A2%E8%AF%95/MySQL/"},{"name":"GitHub","slug":"教程/GitHub","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/GitHub/"},{"name":"Blog","slug":"教程/Blog","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Blog/"},{"name":"Git","slug":"教程/Git","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Git/"},{"name":"问题","slug":"问题","permalink":"https://hutaozhang.github.io/categories/%E9%97%AE%E9%A2%98/"},{"name":"Git","slug":"问题/Git","permalink":"https://hutaozhang.github.io/categories/%E9%97%AE%E9%A2%98/Git/"},{"name":"Hexo","slug":"问题/Hexo","permalink":"https://hutaozhang.github.io/categories/%E9%97%AE%E9%A2%98/Hexo/"},{"name":"Ninx","slug":"教程/Ninx","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Ninx/"},{"name":"Linux","slug":"教程/Linux","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Linux/"},{"name":"Jedis","slug":"教程/Jedis","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Jedis/"},{"name":"Redis","slug":"教程/Redis","permalink":"https://hutaozhang.github.io/categories/%E6%95%99%E7%A8%8B/Redis/"}],"tags":[{"name":"事务","slug":"事务","permalink":"https://hutaozhang.github.io/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"Transaction","slug":"Transaction","permalink":"https://hutaozhang.github.io/tags/Transaction/"},{"name":"Spring","slug":"Spring","permalink":"https://hutaozhang.github.io/tags/Spring/"},{"name":"数据库","slug":"数据库","permalink":"https://hutaozhang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"索引","slug":"索引","permalink":"https://hutaozhang.github.io/tags/%E7%B4%A2%E5%BC%95/"},{"name":"Index","slug":"Index","permalink":"https://hutaozhang.github.io/tags/Index/"},{"name":"MySQL","slug":"MySQL","permalink":"https://hutaozhang.github.io/tags/MySQL/"},{"name":"Database","slug":"Database","permalink":"https://hutaozhang.github.io/tags/Database/"},{"name":"面试","slug":"面试","permalink":"https://hutaozhang.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"MVCC","slug":"MVCC","permalink":"https://hutaozhang.github.io/tags/MVCC/"},{"name":"ACID","slug":"ACID","permalink":"https://hutaozhang.github.io/tags/ACID/"},{"name":"Git","slug":"Git","permalink":"https://hutaozhang.github.io/tags/Git/"},{"name":"GitHub","slug":"GitHub","permalink":"https://hutaozhang.github.io/tags/GitHub/"},{"name":"Hexo","slug":"Hexo","permalink":"https://hutaozhang.github.io/tags/Hexo/"},{"name":"优化","slug":"优化","permalink":"https://hutaozhang.github.io/tags/%E4%BC%98%E5%8C%96/"},{"name":"命令","slug":"命令","permalink":"https://hutaozhang.github.io/tags/%E5%91%BD%E4%BB%A4/"},{"name":"问题","slug":"问题","permalink":"https://hutaozhang.github.io/tags/%E9%97%AE%E9%A2%98/"},{"name":"Nginx","slug":"Nginx","permalink":"https://hutaozhang.github.io/tags/Nginx/"},{"name":"Docker","slug":"Docker","permalink":"https://hutaozhang.github.io/tags/Docker/"},{"name":"服务器","slug":"服务器","permalink":"https://hutaozhang.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"Linux","slug":"Linux","permalink":"https://hutaozhang.github.io/tags/Linux/"},{"name":"Redis","slug":"Redis","permalink":"https://hutaozhang.github.io/tags/Redis/"},{"name":"Jedis","slug":"Jedis","permalink":"https://hutaozhang.github.io/tags/Jedis/"},{"name":"Java","slug":"Java","permalink":"https://hutaozhang.github.io/tags/Java/"}]}